
@article{opara2016critical,
	title = {Critical analysis of vendor lock-in and its impact on cloud computing migration: a business perspective},
	volume = {5},
	pages = {1--18},
	journaltitle = {Journal of Cloud Computing},
	author = {Opara-Martins, Justice and Sahandi, Reza and Tian, Feng},
	date = {2016},
	note = {Publisher: Springer},
}

@online{noauthor_configure_nodate,
	title = {Configure a Security Context for a Pod or Container},
	url = {https://kubernetes.io/docs/tasks/configure-pod-container/security-context/},
	abstract = {A security context defines privilege and access control settings for a Pod or Container. Security context settings include, but are not limited to:
Discretionary Access Control: Permission to access an object, like a file, is based on user {ID} ({UID}) and group {ID} ({GID}).
Security Enhanced Linux ({SELinux}): Objects are assigned security labels.
Running as privileged or unprivileged.
Linux Capabilities: Give a process some privileges, but not all the privileges of the root user.},
	titleaddon = {Kubernetes},
	urldate = {2024-11-23},
	langid = {english},
	note = {Section: docs},
}

@online{noauthor_managing_nodate,
	title = {Managing Security Context Constraints {\textbar} Authentication {\textbar} {OpenShift} Container Platform 4.1},
	url = {https://docs.openshift.com/container-platform/4.1/authentication/managing-security-context-constraints.html},
	urldate = {2024-11-23},
}

@online{noauthor_chapter_nodate,
	title = {Chapter 23. {OVN}-Kubernetes network plugin {\textbar} Red Hat Product Documentation},
	url = {https://docs.redhat.com/en/documentation/openshift_container_platform/4.17/html/networking/ovn-kubernetes-network-plugin},
	urldate = {2024-11-23},
}

@online{noauthor_network_nodate,
	title = {Network overview {\textbar} Google Kubernetes Engine ({GKE})},
	url = {https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview},
	abstract = {This guide explains networking in Google Kubernetes Engine ({GKE}).},
	titleaddon = {Google Cloud},
	urldate = {2024-11-23},
	langid = {english},
}

@online{noauthor_chapter_nodate-1,
	title = {Chapter 4. Planning your environment according to object maximums {\textbar} Red Hat Product Documentation},
	url = {https://docs.redhat.com/en/documentation/openshift_container_platform/4.17/html/scalability_and_performance/planning-your-environment-according-to-object-maximums#cluster-maximums-major-releases_object-limits},
	urldate = {2024-11-23},
}

@online{noauthor_chapter_nodate-2,
	title = {Chapter 6. Planning your environment according to object maximums {\textbar} Red Hat Product Documentation},
	url = {https://docs.redhat.com/en/documentation/openshift_container_platform/4.1/html/scalability_and_performance/planning-your-environment-according-to-object-maximums#cluster-maximums_object-limits},
	urldate = {2024-11-23},
}

@online{noauthor_rhba-20190758_nodate,
	title = {{RHBA}-2019:0758 - Bug Fix Advisory - Red Hat Customer Portal},
	url = {https://access.redhat.com/errata/RHBA-2019:0758},
	urldate = {2024-11-23},
}

@online{noauthor_chapter_nodate-3,
	title = {Chapter 4. Planning your environment according to object maximums {\textbar} Red Hat Product Documentation},
	url = {https://docs.redhat.com/en/documentation/openshift_container_platform/4.17/html/scalability_and_performance/planning-your-environment-according-to-object-maximums#cluster-maximums-major-releases_object-limits},
	urldate = {2024-11-23},
}

@online{noauthor_managing_nodate-1,
	title = {Managing the maximum number of pods per node - Working with nodes {\textbar} Nodes {\textbar} {OpenShift} Container Platform 4.17},
	url = {https://docs.openshift.com/container-platform/4.17/nodes/nodes/nodes-nodes-managing-max-pods.html},
	urldate = {2024-11-23},
}

@online{noauthor_red_nodate,
	title = {Red Hat Enterprise Linux {CoreOS} {\textbar} Architecture {\textbar} {OpenShift} Container Platform 4.16},
	url = {https://docs.openshift.com/container-platform/4.16/architecture/architecture-rhcos.html},
	urldate = {2024-11-23},
}

@inproceedings{8520305,
	title = {Virtualization in cloud computing: Developments and trends},
	doi = {10.1109/ICNGCIS.2017.10},
	pages = {24--28},
	booktitle = {2017 international conference on next generation computing and information systems ({ICNGCIS})},
	author = {Odun-Ayo, Isaac and Ajayi, Olasupo and Okereke, Chinonso},
	date = {2017},
	keywords = {Applications, Cloud computing, Hardware, Market research, Operating systems, Virtual Machines, Virtual machine monitors, Virtual machining, Virtualization},
}

@article{premsankar2018edge,
	title = {Edge computing for the Internet of Things: A case study},
	volume = {5},
	pages = {1275--1284},
	number = {2},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Premsankar, Gopika and Di Francesco, Mario and Taleb, Tarik},
	date = {2018},
	note = {Publisher: {IEEE}},
}

@online{noauthor_using_nodate,
	title = {Using Minikube to Create a Cluster},
	url = {https://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/},
	abstract = {Learn what a Kubernetes cluster is.
Learn what Minikube is.
Start a Kubernetes cluster.},
	titleaddon = {Kubernetes},
	urldate = {2024-11-21},
	langid = {english},
	note = {Section: docs},
}

@online{noauthor_nodes_nodate,
	title = {Nodes},
	url = {https://kubernetes.io/docs/concepts/architecture/nodes/},
	abstract = {Kubernetes runs your workload by placing containers into Pods to run on Nodes. A node may be a virtual or physical machine, depending on the cluster. Each node is managed by the control plane and contains the services necessary to run Pods.
Typically you have several nodes in a cluster; in a learning or resource-limited environment, you might have only one node.
The components on a node include the kubelet, a container runtime, and the kube-proxy.},
	titleaddon = {Kubernetes},
	urldate = {2024-11-21},
	langid = {english},
	note = {Section: docs},
}

@online{noauthor_history_nodate,
	title = {The History of Containers},
	url = {https://www.redhat.com/en/blog/history-containers},
	abstract = {Given the recent massive spike in interest in Linux Containers, you could be forgiven for wondering, “Why now?”. It has been argued that the increasingly prevalent cloud computing model more closely resembles hosting providers than traditional enterprise {IT}, and that containers are a perfect match for this model.Despite the sudden ubiquity of container technology, like so much in the world of open source software, containerization depends on a long series of previous innovations, especially in the operating system. “One cannot resist an idea whose time has come.” Containers are such an idea, one that has been a long time coming.Early {DaysThe} year 2000 was a busy one in the world of computing. 15 years ago, Bill Gates stood aside for Steve Balmer at Microsoft. The {NASDAQ} Composite stock market index peaked at 5132.52, the beginning of the end for the dot-com boom. The patent on the {RSA} cryptographic algorithm ended and the last Multics (Multiplexed Information and Computing Service) got turned off. And jails, an early implementation of container technology, was added to {FreeBSD}.In 2001, container technology made it to the Linux side of the house. Jacques Gélinas created the {VServer} project, which according to the 0.0 version’s change log allowed “running several general purpose Linux server on a single box with a high degree of Independence and security.”The Linux-{VServer} solution was the first effort on Linux to “separate the user-space environment into distinct units (Virtual Private Servers) in such a way that each {VPS} looks and feels like a real server to the processes contained within.” And though the Linux-{VServer} project lacked process migration and clustering, its real weakness was that it required a patched kernel, imposing an additional overhead on distributors and system administrators (or is it a feature?).Incremental {InnovationsIt} was Paul Menage’s approach in 2006 of adapting the cpusets mechanism already in the mainline kernel that really moved containerization on Linux forward, requiring minimally intrusive changes with little impact on performance, code quality, complexity, and future compatibility.The result was generic process containers, which were later renamed control groups, or cgroups, to reflect the fact that “this code is an important part of a container solution... it's far from the whole thing.” Cgroups allow processes to be grouped together, and ensure that each group gets a share of memory, {CPU} and disk I/O; preventing any one container from monopolizing any of these resources.Under former Red Hat Linux kernel developer and a principal software engineer Tejun Heo’s stewardship, cgroups underwent a massive redesign, replacing multiple, per-controller cgroup hierarchies with a “single kernel cgroup hierarchy… allow controllers to be individually enabled for each cgroup” and is the “private property of systemd.” These changes, especially when combined with functionality in systemd, increased the consistency and manageability of cgroups.Kernel namespaces are another key part of a container solution, with Red Hatter Eric W. Biederman’s 2008 user namespaces patches being arguably the most complex and one of the most important namespaces in the context of containers. The implementation of user namespaces allows a process to have it’s own set of users and in particular to allows a process root privileges inside a container, but not outside.Security {ConcernsThe} Linux Containers project ({LXC}), created by engineers from {IBM} around 2008, layered some userspace tooling on top of cgroups and namespaces. While the {LXC} provided an improved user experience around containers, it had some people asking “Are {LXC} containers enough?”Of particular concern was security, because the “{DAC} (discretionary access control) system on which {LXC} relie for all security is known to be incomplete and so it is entirely possible to accidentally/intentionally break out of the container and/or impose a {DOS} attack on the host {OS}.”Since the 1.0 release of {LXC} in early 2014, the situation improved as {LXC} began leveraging some longstanding Linux security technologies. In addition to security features in cgroups and namespaces, support for {SELinux} and Seccomp were added.Seccomp is a Linux kernel feature by Red Hat’s Andrea Arcangeli for limiting the system calls which a task can use. The intent was to allow underutilised {CPU} to be rented out to untrusted guests without fearing they’d abuse other resources, an idea that maps to the container use case.{SELinux} is the mandatory access control ({MAC}) system developed by a consortium of companies and government agencies that is really good at “labeling processes, files, and devices at defining rules on how labeled processes interact with labeled processes, files, and devices.” Linux containers, as a group of processes, are a good match for hardening with {SELinux}.Common Packaging {FormatThe} genesis of the current Linux Container craze is of course the open source Docker project and associated Docker container format. Docker built on all of the incremental developments that came before it and upped the ante by (originally) wrapping the {LXC} userspace tools with even easier to use tooling aimed at developers looking for simple ways to package their applications.In June 2015, Docker the company, the largest contributor to Docker the project (Red Hat is the second), donated the project’s existing codebase to the Open Container Initiative, a lightweight governance structure under the auspices of the Linux Foundation created to prevent fragmentation and promote open standards by “cloud giants” including Red Hat. Maintainers of both libcontainer and appc, the donated codebase, form a technical advisory board that will guide and drive the project. Red Hat is proud to have one of our own, Vincent Batts, helping to guide the Initiative’s technical direction.Orchestrating at {ScaleOne} of the biggest challenges for those working with containers today is how to deploy and orchestrate containers at scale. While a number of approaches are emerging, the one that is gaining the most traction is Kubernetes. When Kubernetes launched in 2014, Google discussed how “everything at Google runs in a container” to support their various service offerings and made news when they revealed that they were starting “over 2 billion containers per week.” Google outlined details on the lineage of the Kubernetes project which is traced from Borg, Google’s internal container cluster-management system.Over the past year, Red Hat has contributed substantially to Kubernetes in various areas, as we work to bring the concepts of atomic, immutable infrastructure to enterprise customers in products like {OpenShift}, Red Hat Enterprise Linux and {RHEL} Atomic Host. Many of the Google developers that Red Hat collaborates with today in the Kubernetes community were previously developers on the Borg project. As we work with Google and others to bring Kubernetes to enterprise users, we benefit greatly from their experience as they bring the best ideas from Borg into Kubernetes and learn from its shortcomings.Looking {AheadDespite} the long history of incremental innovations, recent advancements in Linux around Linux containers are revolutionizing the way that companies will develop, consume, and manage applications. As with traditional applications, containerized applications interact with and depend on the operating system.Future innovations in the containerization of applications will build on incremental improvements to the Linux operating system, as they have all along. Red Hat’s container strategy helps {IT} deliver applications to accelerate business agility, developer productivity, and deployment flexibility across hybrid cloud environments.},
	urldate = {2024-11-21},
	langid = {english},
}

@inproceedings{7830738,
	title = {{QoS} assurance with light virtualization - a survey},
	doi = {10.1109/CloudCom.2016.0097},
	pages = {558--563},
	booktitle = {2016 {IEEE} international conference on cloud computing technology and science ({CloudCom})},
	author = {Heidari, Parisa and Lemieux, Yves and Shami, Abdallah},
	date = {2016},
	keywords = {Aurora, Cloud Computing, Cloud computing, Containers, Fleet, Kernel, Kubernetes, Light virtualization, Linux Container, Marathon, Mesos, Quality of Service ({QoS}), Quality of service, Resource management, Swarm, Virtualization},
}

@article{1236471,
	title = {Web services orchestration and choreography},
	volume = {36},
	doi = {10.1109/MC.2003.1236471},
	pages = {46--52},
	number = {10},
	journaltitle = {Computer},
	author = {Peltz, C.},
	date = {2003},
	keywords = {Availability, Collaboration, Companies, Computer architecture, Engines, Information technology, Logic, Process design, Scalability, Web services},
}

@inproceedings{isard2009quincy,
	title = {Quincy: fair scheduling for distributed computing clusters},
	pages = {261--276},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 22nd symposium on operating systems principles},
	author = {Isard, Michael and Prabhakaran, Vijayan and Currey, Jon and Wieder, Udi and Talwar, Kunal and Goldberg, Andrew},
	date = {2009},
}

@book{fehling2014cloud,
	title = {Cloud computing patterns: fundamentals to design, build, and manage cloud applications},
	volume = {545},
	publisher = {Springer},
	author = {Fehling, Christoph and Leymann, Frank and Retter, Ralph and Schupeck, Walter and Arbitter, Peter},
	date = {2014},
}

@online{noauthor_kuberneteskubernetes_nodate,
	title = {kubernetes/kubernetes: Production-Grade Container Scheduling and Management},
	url = {https://github.com/kubernetes/kubernetes},
	urldate = {2024-11-01},
}

@article{kratzke2014lightweight,
	title = {A lightweight virtualization cluster reference architecture derived from open source paas platforms},
	volume = {1},
	pages = {17--30},
	number = {2},
	journaltitle = {Open Journal of Mobile Computing and Cloud Computing},
	author = {Kratzke, Nane},
	date = {2014},
}

@article{goldberg_survey_1974,
	title = {Survey of virtual machine research},
	volume = {7},
	issn = {1558-0814},
	url = {https://ieeexplore.ieee.org/document/6323581/?arnumber=6323581},
	doi = {10.1109/MC.1974.6323581},
	abstract = {The complete instruction-by-instruction simulation of one computer system on a different system is a well-known computing technique. It is often used for software development when a hardware base is being altered. For example, if a programmer is developing software for some new special purpose (e.g., aerospace) computer X which is under construction and as yet unavailable, he will likely begin by writing a simulator for that computer on some available general-purpose machine G. The simulator will provide a detailed simulation of the special-purpose environment X, including its processor, memory, and I/O devices. Except for possible timing dependencies, programs which run on the “simulated machine X” can later run on the “real machine X” (when it is finally built and checked out) with identical effect. The programs running on X can be arbitrary — including code to exercise simulated I/O devices, move data and instructions anywhere in simulated memory, or execute any instruction of the simulated machine. The simulator provides a layer of software filtering which protects the resources of the machine G from being misused by programs on X.},
	pages = {34--45},
	number = {6},
	journaltitle = {Computer},
	author = {Goldberg, Robert P.},
	urldate = {2024-10-31},
	date = {1974-06},
	note = {Conference Name: Computer},
	keywords = {Computational modeling, Computer architecture, Computers, Hardware, Operating systems, Virtual machining},
}

@article{bernstein_containers_2014,
	title = {Containers and Cloud: From {LXC} to Docker to Kubernetes},
	volume = {1},
	issn = {2325-6095},
	url = {https://ieeexplore.ieee.org/document/7036275},
	doi = {10.1109/MCC.2014.51},
	shorttitle = {Containers and Cloud},
	abstract = {This issue's "Cloud Tidbit" focuses on container technology and how it's emerging as an important part of the cloud computing infrastructure. It looks at Docker, an open source project that automates the faster deployment of Linux applications, and Kubernetes, an open source cluster manager for Docker containers.},
	pages = {81--84},
	number = {3},
	journaltitle = {{IEEE} Cloud Computing},
	author = {Bernstein, David},
	urldate = {2024-10-24},
	date = {2014-09},
	note = {Conference Name: {IEEE} Cloud Computing},
	keywords = {Cloud computing, Containers, Google, Home appliances, Linux, Runtime, Virtual machine monitors, cloud, containers, dockers, virtual machines},
}

@inproceedings{soltesz_container-based_2007,
	location = {New York, {NY}, {USA}},
	title = {Container-based operating system virtualization: a scalable, high-performance alternative to hypervisors},
	isbn = {978-1-59593-636-3},
	url = {https://dl.acm.org/doi/10.1145/1272996.1273025},
	doi = {10.1145/1272996.1273025},
	series = {{EuroSys} '07},
	shorttitle = {Container-based operating system virtualization},
	abstract = {Hypervisors, popularized by Xen and {VMware}, are quickly becoming commodity. They are appropriate for many usage scenarios, but there are scenarios that require system virtualization with high degrees of both isolation and efficiency. Examples include {HPC} clusters, the Grid, hosting centers, and {PlanetLab}. We present an alternative to hypervisors that is better suited to such scenarios. The approach is a synthesis of prior work on resource containers and security containers applied to general-purpose, time-shared operating systems. Examples of such container-based systems include Solaris 10, Virtuozzo for Linux, and Linux-{VServer}. As a representative instance of container-based systems, this paper describes the design and implementation of Linux-{VServer}. In addition, it contrasts the architecture of Linux-{VServer} with current generations of Xen, and shows how Linux-{VServer} provides comparable support for isolation and superior system efficiency.},
	pages = {275--287},
	booktitle = {Proceedings of the 2nd {ACM} {SIGOPS}/{EuroSys} European Conference on Computer Systems 2007},
	publisher = {Association for Computing Machinery},
	author = {Soltesz, Stephen and Pötzl, Herbert and Fiuczynski, Marc E. and Bavier, Andy and Peterson, Larry},
	urldate = {2024-10-24},
	date = {2007-03-21},
}

@article{soltesz_container-based_2007-1,
	title = {Container-based operating system virtualization: a scalable, high-performance alternative to hypervisors},
	volume = {41},
	issn = {0163-5980},
	url = {https://doi.org/10.1145/1272998.1273025},
	doi = {10.1145/1272998.1273025},
	shorttitle = {Container-based operating system virtualization},
	abstract = {Hypervisors, popularized by Xen and {VMware}, are quickly becoming commodity. They are appropriate for many usage scenarios, but there are scenarios that require system virtualization with high degrees of both isolation and efficiency. Examples include {HPC} clusters, the Grid, hosting centers, and {PlanetLab}. We present an alternative to hypervisors that is better suited to such scenarios. The approach is a synthesis of prior work on resource containers and security containers applied to general-purpose, time-shared operating systems. Examples of such container-based systems include Solaris 10, Virtuozzo for Linux, and Linux-{VServer}. As a representative instance of container-based systems, this paper describes the design and implementation of Linux-{VServer}. In addition, it contrasts the architecture of Linux-{VServer} with current generations of Xen, and shows how Linux-{VServer} provides comparable support for isolation and superior system efficiency.},
	pages = {275--287},
	number = {3},
	journaltitle = {{SIGOPS} Oper. Syst. Rev.},
	author = {Soltesz, Stephen and Pötzl, Herbert and Fiuczynski, Marc E. and Bavier, Andy and Peterson, Larry},
	urldate = {2024-10-24},
	date = {2007-03-21},
}

@article{pahl_containerization_2015,
	title = {Containerization and the {PaaS} Cloud},
	volume = {2},
	issn = {2325-6095},
	url = {https://ieeexplore.ieee.org/document/7158965},
	doi = {10.1109/MCC.2015.51},
	abstract = {Containerization is widely discussed as a lightweight virtualization solution. Apart from exhibiting benefits over traditional virtual machines in the cloud, containers are especially relevant for platform-as-a-service ({PaaS}) clouds to manage and orchestrate applications through containers as an application packaging mechanism. This article discusses the requirements that arise from having to facilitate applications through distributed multicloud platforms.},
	pages = {24--31},
	number = {3},
	journaltitle = {{IEEE} Cloud Computing},
	author = {Pahl, Claus},
	urldate = {2024-10-24},
	date = {2015-05},
	note = {Conference Name: {IEEE} Cloud Computing},
	keywords = {Computer architecture, Containerization, Docker, File systems, Kubernetes, Linux, {PaaS}, Packaging, Virtualization, cloud, cloud computing, cluster, container, multicloud, virtualization},
}

@inproceedings{huang_achieving_2014,
	title = {Achieving big data privacy via hybrid cloud},
	url = {https://ieeexplore.ieee.org/document/6849284},
	doi = {10.1109/INFCOMW.2014.6849284},
	abstract = {Nowadays the amount of data is being produced exponentially with the rapid development of electronic technology and communication, which makes it hard to cost-effectively store and manage these big data. Cloud computing, a new business model, is considered as one of most attractive solutions for big data, and provides the advantage of reduced cost through sharing of computing and storage resources. However, the growing concerns in term of the privacy of data stored in public cloud have slowed down the adoption of cloud computing for big data because sensitive information may be contained among the big data or the data owner themselves do not want any other people to scan their data. Since the data volume is huge and mobile devices are widely used, the traditional cryptographic approach are not suitable for big data. In this paper, we propose an efficient scheme for image data, which has much more volume than text data. We evaluate our scheme in real networks (including Amazon {EC}2), and our experimental results on image show that: (1) our scheme achieves privacy but only use 1/585.8 1/398.6 the time of the {AES} algorithm; (2) the delay of our hybrid-cloud-based scheme is only 3\% 5\% more than that of the traditional public-cloud-only approach.},
	eventtitle = {2014 {IEEE} Conference on Computer Communications Workshops ({INFOCOM} {WKSHPS})},
	pages = {512--517},
	booktitle = {2014 {IEEE} Conference on Computer Communications Workshops ({INFOCOM} {WKSHPS})},
	author = {Huang, Xueli and Du, Xiaojiang},
	urldate = {2024-10-20},
	date = {2014-04},
	keywords = {Big data, Cloud computing, Conferences, Cryptography, Data privacy, Indexes, big data, cloud computing, data privacy, hybrid cloud, image, security},
}

@inproceedings{gibson_benefits_2012,
	title = {Benefits and challenges of three cloud computing service models},
	url = {https://ieeexplore.ieee.org/abstract/document/6412402},
	doi = {10.1109/CASoN.2012.6412402},
	abstract = {Cloud computing can be defined as the use of new or existing computing hardware and virtualization technologies to form a shared infrastructure that enables web-based value added services. The three predominant service models are infrastructure, platform, and software-asa-service. Infrastructure-as-a-Service ({IaaS}) can be defined as the use of servers, storage, and virtualization to enable utility like services for users. Security is a big concern within {IaaS}, especially considering that the rest of the cloud service models run on top of the infrastructure and related layers. Platform-as-a-Service ({PaaS}) providers offer access to {APIs}, programming languages and development middleware which allows subscribers to develop custom applications without installing or configuring the development environment. Software-as-a-Service ({SaaS}) gives subscribed or pay-peruse users access to software or services which reside in the cloud and not on the user's device. Understanding the cloud service models is critical in determining if cloud services or hosting are an appropriate business solution, and if so, which model best balances the level of control required versus reduced hardware, configuration, and maintenance costs. Cloud computing offers many benefits to organizations; it has enabled collaboration amongst disparate communities and workgroups, and has overcome challenges that have plagued existing business solutions. However, the security, privacy, and integrity of the cloud are of prime importance and there are many challenges that exist. At the present time there seems to be a lot of momentum behind the adoption of cloud computing despite these. This may simply be a trend, an indication that society truly wants their data to be available whenever from anywhere, or a sign that few understand the associated risks.},
	eventtitle = {2012 Fourth International Conference on Computational Aspects of Social Networks ({CASoN})},
	pages = {198--205},
	booktitle = {2012 Fourth International Conference on Computational Aspects of Social Networks ({CASoN})},
	author = {Gibson, Joel and Rondeau, Robin and Eveleigh, Darren and Tan, Qing},
	urldate = {2024-10-20},
	date = {2012-11},
	keywords = {Cloud computing, Computational modeling, Educational institutions, Hardware, {IaaS}, {PaaS}, {SaaS}, Security, Software as a service, cloud benefits, cloud challenges, cloud computing, cloud layers, clouds, infrastructure as a service, platform as a service, privacy, security, service oriented, software as a service},
}

@online{noauthor_red_nodate-1,
	title = {Red Hat {OpenShift} pricing},
	url = {https://www.redhat.com/en/technologies/cloud-computing/openshift/pricing},
	abstract = {Learn about plans and pricing for self-managed and fully managed options for Red Hat {OpenShift}.},
	urldate = {2024-10-20},
	langid = {english},
}

@online{editor_cloud_nodate,
	title = {cloud computing - Glossary {\textbar} {CSRC}},
	url = {https://csrc.nist.gov/glossary/term/cloud_computing},
	abstract = {{CSRC} Home Page},
	author = {Editor, {CSRC} Content},
	urldate = {2024-10-20},
}

@article{brohi2011challenges,
	title = {Challenges and benefits for adopting the paradigm of cloud computing},
	volume = {8},
	pages = {286--290},
	number = {2},
	journaltitle = {International Journal of Advanced Engineering Sciences and Technologies},
	author = {Brohi, Sarfraz Nawaz and Bamiah, Mervat Adib},
	date = {2011},
}

@inproceedings{jadeja_cloud_2012,
	title = {Cloud computing - concepts, architecture and challenges},
	url = {https://ieeexplore.ieee.org/abstract/document/6203873},
	doi = {10.1109/ICCEET.2012.6203873},
	abstract = {With the advent internet in the 1990s to the present day facilities of ubiquitous computing, the internet has changed the computing world in a drastic way. It has traveled from the concept of parallel computing to distributed computing to grid computing and recently to cloud computing. Although the idea of cloud computing has been around for quite some time, it is an emerging field of computer science. Cloud computing can be defined as a computing environment where computing needs by one party can be outsourced to another party and when need be arise to use the computing power or resources like database or emails, they can access them via internet. Cloud computing is a recent trend in {IT} that moves computing and data away from desktop and portable {PCs} into large data centers. The main advantage of cloud computing is that customers do not have to pay for infrastructure, its installation, required man power to handle such infrastructure and maintenance. In this paper we will discuss what makes all this possible, what is the architectural design of cloud computing and its applications.},
	eventtitle = {2012 International Conference on Computing, Electronics and Electrical Technologies ({ICCEET})},
	pages = {877--880},
	booktitle = {2012 International Conference on Computing, Electronics and Electrical Technologies ({ICCEET})},
	author = {Jadeja, Yashpalsinh and Modi, Kirit},
	urldate = {2024-10-20},
	date = {2012-03},
	keywords = {Browsers, Communities, Computational modeling, History, Lead, Monitoring, Reliability, applications, architecture, business component of cloud computing, cloud computing, issues},
}

@article{dash2016governance,
	title = {E-Governance paradigm using cloud infrastructure: Benefits and challenges},
	volume = {85},
	pages = {843--855},
	journaltitle = {Procedia Computer Science},
	author = {Dash, Satyabrata and Pani, Subhendu Kumar},
	date = {2016},
	note = {Publisher: Elsevier},
}

@article{suleiman2012understanding,
	title = {On understanding the economics and elasticity challenges of deploying business applications on public cloud infrastructure},
	volume = {3},
	pages = {173--193},
	journaltitle = {Journal of Internet Services and Applications},
	author = {Suleiman, Basem and Sakr, Sherif and Jeffery, Ross and Liu, Anna},
	date = {2012},
	note = {Publisher: Springer},
}

@online{noauthor_kubernetes_nodate,
	title = {Kubernetes platform comparison: Red Hat {OpenShift}, {SUSE} Rancher and Canonical Kubernetes},
	url = {https://ubuntu.com/engage/enterprise-kubernetes-comparison},
	shorttitle = {Kubernetes platform comparison},
	abstract = {How to choose the right Kubernetes distribution for your business},
	titleaddon = {Ubuntu},
	urldate = {2024-10-20},
	langid = {english},
}

@article{truyen_managing_2020,
	title = {Managing Feature Compatibility in Kubernetes: Vendor Comparison and Analysis},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/abstract/document/9298825},
	doi = {10.1109/ACCESS.2020.3045768},
	shorttitle = {Managing Feature Compatibility in Kubernetes},
	abstract = {Kubernetes (k8s) is a kind of cluster operating system for cloud-native workloads that has become a de-facto standard for container orchestration. Provided by more than one hundred vendors, it has the potential to protect the customer from vendor lock-in. However, the open-source k8s distribution consists of many optional and alternative features that must be explicitly activated and may depend on pre-configured system components. As a result, incompatibilities still may ensue among Kubernetes vendors. Mostly managed k8s services typically restrict the customizability of Kubernetes. This paper firstly compares the most relevant k8s vendors and, secondly, analyses the potential of Kubernetes to detect and configure compatible support for required features across vendors in a uniform manner. Our comparison is performed based on documented features, by testing, and by inspection of the configuration state of running clusters. Our analysis focuses on the potential of the end-to-end testing suite of Kubernetes to detect support for a desired feature in any Kubernetes vendor and the possibility of reconfiguring the studied vendors with missing features in a uniform manner. Our findings are threefold: First, incompatibilities arise between default cluster configurations of the studied vendors for approximately 18\% of documented features. Second, matching end-to-end tests exist only for around 64\% of features and for 17\% of features these matching tests are not well developed for all vendors. Third, almost all feature incompatibilities can be resolved using a vendor-agnostic {API}. These insights are beneficial to avoid feature incompatibilities already in cloud-native application engineering processes. Moreover, the end-to-end testing suite can be extended in currently unlighted areas to provide better feature coverage.},
	pages = {228420--228439},
	journaltitle = {{IEEE} Access},
	author = {Truyen, Eddy and Kratzke, Nane and Van Landuyt, Dimitri and Lagaisse, Bert and Joosen, Wouter},
	urldate = {2024-10-20},
	date = {2020},
	note = {Conference Name: {IEEE} Access},
	keywords = {Cloud computing, Computer systems organization, Configuration management, Containers, Feature extraction, Open source software, Testing, architectures, cloud computing, distributed architectures},
}

@inproceedings{pellegrini_preventing_2017,
	title = {Preventing vendor lock-ins via an interoperable multi-cloud deployment approach},
	url = {https://ieeexplore.ieee.org/abstract/document/8356428},
	doi = {10.23919/ICITST.2017.8356428},
	abstract = {A vendor lock-in makes customers dependent of a propriety product, service or technology provided by a vendor. In terms of cloud services, it is achieved by providing and developing services that are platform-dependent with proprietary technologies, interfaces or formats. This can be a huge barrier to adopt cloud services because customers are tied to specific vendors which prevent portability through proprietary or a limited set of interfaces. As consequence, customers are hindered to alternate venders easily without substantial migration costs. A multi-cloud strategy is one possible way to avoid vendor lock-ins. The scope of the is paper is to design and implement a solution-stack to provide web services which operate independent from proprietary cloud service provider technologies. We provide a solution stack prototype which will support key functionalities such as portability, interoperability and platform-independency by implementing modern technologies and standards.},
	eventtitle = {2017 12th International Conference for Internet Technology and Secured Transactions ({ICITST})},
	pages = {382--387},
	booktitle = {2017 12th International Conference for Internet Technology and Secured Transactions ({ICITST})},
	author = {Pellegrini, Roland and Rottmann, Patrick and Strieder, Georg},
	urldate = {2024-10-20},
	date = {2017-12},
	keywords = {Cloud Computing, Cloud computing, Computer architecture, Containers, Databases, Interoperability, Multi-cloud, Standards organizations, Vendor lock-in},
}

@thesis{finta_mitigating_2022,
	title = {Mitigating the effects of vendor lock-in in edge cloud environments with open-source technologies},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-309339},
	abstract = {{DiVA} portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	type = {phdthesis},
	author = {Finta, Gabor},
	urldate = {2024-10-20},
	date = {2022},
}

@article{quint2016overcome,
	title = {Overcome vendor lock-in by integrating already available container technologies towards transferability in cloud computing for smes},
	volume = {50},
	journaltitle = {Cloud Computing},
	author = {Quint, Peter-Christian and Kratzke, Nane},
	date = {2016},
}

@inproceedings{koziolek_lightweight_2023,
	location = {New York, {NY}, {USA}},
	title = {Lightweight Kubernetes Distributions: A Performance Comparison of {MicroK}8s, k3s, k0s, and Microshift},
	isbn = {9798400700682},
	url = {https://dl.acm.org/doi/10.1145/3578244.3583737},
	doi = {10.1145/3578244.3583737},
	series = {{ICPE} '23},
	shorttitle = {Lightweight Kubernetes Distributions},
	abstract = {With containers becoming a prevalent method of software deployment, there is an increasing interest to use container orchestration frameworks not only in data centers, but also on resource-constrained hardware, such as Internet-of-Things devices, Edge gateways, or developer workstations. Consequently, software vendors have released several lightweight Kubernetes (K8s) distributions for container orchestration in the last few years, but it remains difficult for software developers to select an appropriate solution. Existing studies on lightweight K8s distribution performance tested only small workloads, showed inconclusive results, and did not cover recently released distributions. The contribution of this paper is a comparison of {MicroK}8s, k3s, k0s, and {MicroShift}, investigating their minimal resource usage as well as control plane and data plane performance in stress scenarios. While k3s and k0s showed by a small amount the highest control plane throughput and {MicroShift} showed the highest data plane throughput, usability, security, and maintainability are additional factors that drive the decision for an appropriate distribution.},
	pages = {17--29},
	booktitle = {Proceedings of the 2023 {ACM}/{SPEC} International Conference on Performance Engineering},
	publisher = {Association for Computing Machinery},
	author = {Koziolek, Heiko and Eskandani, Nafise},
	urldate = {2024-10-19},
	date = {2023-04-15},
}

@inproceedings{felter_updated_2015,
	title = {An updated performance comparison of virtual machines and Linux containers},
	url = {https://ieeexplore.ieee.org/abstract/document/7095802?casa_token=6rmU2pnnyLgAAAAA:35C3QzsWXHetTiMtArkutx9Rxi1RQHBrr39MMb3DrakCxcXSpDPgZ5-8tD1LnZhZOIf3kZBOgw},
	doi = {10.1109/ISPASS.2015.7095802},
	abstract = {Cloud computing makes extensive use of virtual machines because they permit workloads to be isolated from one another and for the resource usage to be somewhat controlled. In this paper, we explore the performance of traditional virtual machine ({VM}) deployments, and contrast them with the use of Linux containers. We use {KVM} as a representative hypervisor and Docker as a container manager. Our results show that containers result in equal or better performance than {VMs} in almost all cases. Both {VMs} and containers require tuning to support I/Ointensive applications. We also discuss the implications of our performance results for future cloud architectures.},
	eventtitle = {2015 {IEEE} International Symposium on Performance Analysis of Systems and Software ({ISPASS})},
	pages = {171--172},
	booktitle = {2015 {IEEE} International Symposium on Performance Analysis of Systems and Software ({ISPASS})},
	author = {Felter, Wes and Ferreira, Alexandre and Rajamony, Ram and Rubio, Juan},
	urldate = {2024-10-15},
	date = {2015-03},
	keywords = {Containers, Hardware, Linux, Random access memory, Servers, Throughput, Virtual machining},
}

@online{canonical_kubernetes_2022,
	title = {Kubernetes and cloud native operations report 2022},
	url = {https://juju.is},
	abstract = {Juju is an open source orchestration engine for software operators that enables the deployment, integration and lifecycle management of applications at any scale, on any infrastructure},
	titleaddon = {Juju},
	author = {{Canonical}},
	urldate = {2024-09-29},
	date = {2022},
	langid = {english},
}

@online{noauthor_10_2024,
	title = {10 Years of Kubernetes},
	url = {https://kubernetes.io/blog/2024/06/06/10-years-of-kubernetes/},
	abstract = {Ten (10) years ago, on June 6th, 2014, the first commit of Kubernetes was pushed to {GitHub}. That first commit with 250 files and 47,501 lines of go, bash and markdown kicked off the project we have today. Who could have predicted that 10 years later, Kubernetes would grow to become one of the largest Open Source projects to date with over 88,000 contributors from more than 8,000 companies, across 44 countries.},
	titleaddon = {Kubernetes},
	urldate = {2024-09-15},
	date = {2024-06-06},
	langid = {english},
}

@article{truyen_comprehensive_2019,
	title = {A Comprehensive Feature Comparison Study of Open-Source Container Orchestration Frameworks},
	volume = {9},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	doi = {10.3390/app9050931},
	abstract = {(1) Background: Container orchestration frameworks provide support for management of complex distributed applications. Different frameworks have emerged only recently, and they have been in constant evolution as new features are being introduced. This reality makes it difficult for practitioners and researchers to maintain a clear view of the technology space. (2) Methods: we present a descriptive feature comparison study of the three most prominent orchestration frameworks: Docker Swarm, Kubernetes, and Mesos, which can be combined with Marathon, Aurora or {DC}/{OS}. This study aims at (i) identifying the common and unique features of all frameworks, (ii) comparing these frameworks qualitatively and quantitatively with respect to genericity in terms of supported features, and (iii) investigating the maturity and stability of the frameworks as well as the pioneering nature of each framework by studying the historical evolution of the frameworks on {GitHub}. (3) Results: (i) we have identified 124 common features and 54 unique features that we divided into a taxonomy of 9 functional aspects and 27 functional sub-aspects. (ii) Kubernetes supports the highest number of accumulated common and unique features for all 9 functional aspects; however, no evidence has been found for significant differences in genericity with Docker Swarm and {DC}/{OS}. (iii) Very little feature deprecations have been found and 15 out of 27 sub-aspects have been identified as mature and stable. These are pioneered in descending order by Kubernetes, Mesos, and Marathon. (4) Conclusion: there is a broad and mature foundation that underpins all container orchestration frameworks. Likely areas for further evolution and innovation include system support for improved cluster security and container security, performance isolation of {GPU}, disk and network resources, and network plugin architectures.},
	pages = {931},
	number = {5},
	journaltitle = {Applied Sciences},
	author = {Truyen, Eddy and Van Landuyt, Dimitri and Preuveneers, Davy and Lagaisse, Bert and Joosen, Wouter},
	date = {2019-01},
	langid = {english},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {commonality and variability analysis, container orchestration frameworks, feature deprecation risk, genericity, maturity of features, middleware for cloud-native applications},
}

@online{noauthor_red_nodate-2,
	title = {Red Hat {OpenShift} vs. Kubernetes: What's the difference?},
	url = {https://www.redhat.com/en/technologies/cloud-computing/openshift/red-hat-openshift-kubernetes},
	shorttitle = {Red Hat {OpenShift} vs. Kubernetes},
	abstract = {Red Hat® {OpenShift}® is a certified Kubernetes powered application platform —a commercialized software product built based on multiple open source projects.},
	urldate = {2024-10-04},
	langid = {english},
}

@online{noauthor_what_nodate,
	title = {What is enterprise Kubernetes?},
	url = {https://www.redhat.com/en/topics/containers/what-is-enterprise-kubernetes},
	abstract = {Kubernetes is an open source container orchestration platform. This overview explains the benefits, features, and challenges of Kubernetes for enterprises.},
	urldate = {2024-10-04},
	langid = {english},
}

@online{schaffererin_what_2024,
	title = {What is Azure Kubernetes Service ({AKS})? - Azure Kubernetes Service},
	url = {https://learn.microsoft.com/en-us/azure/aks/what-is-aks},
	shorttitle = {What is Azure Kubernetes Service ({AKS})?},
	abstract = {Learn about the features of Azure Kubernetes Service ({AKS}) and how to get started.},
	author = {schaffererin},
	urldate = {2024-10-04},
	date = {2024-08-01},
	langid = {english},
}

@misc{wermann_ktwin_2024,
	title = {{KTWIN}: A Serverless Kubernetes-based Digital Twin Platform},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2408.01635},
	doi = {10.48550/ARXIV.2408.01635},
	shorttitle = {{KTWIN}},
	abstract = {Digital Twins ({DTs}) systems are virtual representations of physical assets allowing organizations to gain insights and improve existing processes. In practice, {DTs} require proper modeling, coherent development and seamless deployment along cloud and edge landscapes relying on established patterns to reduce operational costs. In this work, we propose {KTWIN} a Kubernetes-based Serverless Platform for Digital Twins. {KTWIN} was developed using the state-of-the-art open-source Cloud Native tools, allowing {DT} operators to easily define models through open standards and configure details of the underlying services and infrastructure. The experiments carried out with the developed prototype show that {KTWIN} can provide a higher level of abstraction to model and deploy a Digital Twin use case without compromising the solution scalability. The tests performed also show cost savings ranging between 60\% and 80\% compared to overprovisioned scenarios.},
	publisher = {{arXiv}},
	author = {Wermann, Alexandre Gustavo and Wickboldt, Juliano Araujo},
	urldate = {2024-10-04},
	date = {2024},
	note = {Version Number: 2},
	keywords = {{FOS}: Computer and information sciences, Networking and Internet Architecture (cs.{NI})},
}

@thesis{juntunen_openshift_2020,
	title = {{OpenShift} from the enterprise fleet management context, comparison},
	rights = {{CC} {BY}-{NC}-{SA} 4.0},
	url = {https://lutpub.lut.fi/handle/10024/161607},
	abstract = {This thesis describes possibilities and compares {OpenShift} against other competing platforms from the virtual infrastructure manager fleet management perspective. The thesis is made for a company. Need for this work are created by phenomenon such as fast rise of the bandwidth heavy internet-based services. In addition, technological shifts such movement from hypervisor-based virtualization towards container-based virtualization and movement from centralized networking towards distributed networking have influenced creation of this work. First this thesis compares {OpenShift} against the suitable competing platforms and analyses whether {OpenShift} is suitable as a virtual infrastructure manager from the fleet management perspective. Next {OpenShift} application programming interfaces are described in a practical manner. Finally, {OpenShift} application programming interfaces are found to be sufficiently broad, and it is stated that {OpenShift} does not cause problems from the fleet management point of view.},
	type = {phdthesis},
	author = {Juntunen, Roni},
	urldate = {2024-10-04},
	date = {2020},
	note = {Accepted: 2020-09-08T03:29:24Z},
}

@thesis{bodhanya_comparing_2022,
	title = {Comparing Cloud Orchestrated Container Platforms : Under the lenses of Performance, Cost, Ease-of-Use, and Reliability},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-490506},
	shorttitle = {Comparing Cloud Orchestrated Container Platforms},
	abstract = {{DiVA} portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	type = {phdthesis},
	author = {Bodhanya, Thameez Ahmad},
	urldate = {2024-10-04},
	date = {2022},
}

@article{alamoush_open_2024,
	title = {Open source container orchestration for Industry 4.0 – requirements and systematic feature analysis},
	volume = {26},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-024-00767-w},
	doi = {10.1007/s10009-024-00767-w},
	abstract = {Container-based virtualization is a popular technique, e.g., to realize microservice architectures. Recently, containers became popular in Industry 4.0 / {IIoT} systems, which typically consist of hundreds of (edge) devices and machines. In such setups, efficient management of containers is essential as offered by container orchestrators like Kubernetes. However, currently no specific overviews discussing orchestrator capabilities for Industry 4.0 are available. In this paper, we analyze nine open source container orchestrators for their application in Industry 4.0 or {IIoT} settings as a basis for future research and development. We contribute a systematic literature review to identify 23 basic orchestration requirements. We complement this by insights from an intensive requirements collection in a research project on intelligent industrial production, as well as selected features from a published generic orchestrator analysis. From these 66 requirements, we derive a requirements/feature taxonomy, which we use to analyze the nine open source orchestrators including Kubernetes. We show that there is, e.g., still a lack of support regarding edge devices, {IIoT} protocols, security mechanisms, and specialized resources for artificial intelligence.},
	pages = {527--550},
	number = {5},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	shortjournal = {Int J Softw Tools Technol Transfer},
	author = {Alamoush, Ahmad and Eichelberger, Holger},
	urldate = {2024-10-04},
	date = {2024-10-01},
	langid = {english},
	keywords = {Artificial Intelligence, Container orchestrators, Feature analysis, Industry 4.0/{IIoT}, Kubernetes, Requirements taxonomy, Systematic review},
}

@inproceedings{linzel_how_2019,
	location = {{USA}},
	title = {How can {OpenShift} accelerate your Kubernetes adoption: a workshop exploring {OpenShift} features},
	series = {{CASCON} '19},
	shorttitle = {How can {OpenShift} accelerate your Kubernetes adoption},
	abstract = {{OpenShift} is a Kubernetes distribution which comes with additional capabilities for developers and operators to make building and running cloud-native applications easier.This hands-on workshop walked the participants through the deployment of an application in an {OpenShift} cluster. Origin Community Distribution of {OpenShift} (referred to as {OKD}) is the Kubernetes distribution that powers {OpenShift}. With Minishift version 3.x, participants can use {OKD} to get some hands-on experience of {OpenShift} locally.In addition to managed Kubernetes clusters, {IBM} Cloud also offers managed {OpenShift} clusters which leverages a lot of the same infrastructure as the Kubernetes clusters. We also demonstrated how to deploy the application into a paid {IBM} Cloud {OpenShift} cluster. We highlighted the similarities and differences between tasks performed in Kubernetes and {OpenShift} to illustrate the value of using {OpenShift}. We compared Kubernetes and {OpenShift} through real example configuration, setup and deployment.},
	pages = {380--381},
	booktitle = {Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
	publisher = {{IBM} Corp.},
	author = {Linzel, Ben and Zhu, Erica and Flores, Geofrey and Liu, John and Dikaleh, Serjik},
	urldate = {2024-10-04},
	date = {2019-11-04},
}

@book{rosso_production_2021,
	title = {Production Kubernetes},
	isbn = {978-1-4920-9227-8},
	abstract = {Kubernetes has become the dominant container orchestrator, but many organizations that have recently adopted this system are still struggling to run actual production workloads. In this practical book, four software engineers from {VMware} bring their shared experiences running Kubernetes in production and provide insight on key challenges and best practices.The brilliance of Kubernetes is how configurable and extensible the system is, from pluggable runtimes to storage integrations. For platform engineers, software developers, infosec, network engineers, storage engineers, and others, this book examines how the path to success with Kubernetes involves a variety of technology, pattern, and abstraction considerations.With this book, you will:Understand what the path to production looks like when using {KubernetesExamine} where gaps exist in your current Kubernetes {strategyLearn} Kubernetes's essential building blocks--and their trade-{offsUnderstand} what's involved in making Kubernetes a viable location for {applicationsLearn} better ways to navigate the cloud native landscape},
	pagetotal = {509},
	publisher = {"O'Reilly Media, Inc."},
	author = {Rosso, Josh and Lander, Rich and Brand, Alex and Harris, John},
	date = {2021-03-16},
	langid = {english},
	note = {Google-Books-{ID}: {WrIlEAAAQBAJ}},
	keywords = {Computers / Distributed Systems / Cloud Computing, Computers / Distributed Systems / General, Computers / Internet / Web Programming, Computers / Internet / Web Services \& {APIs}, Computers / Programming / Open Source, Computers / Software Development \& Engineering / Systems Analysis \& Design},
}

@misc{bryant_kubernetes_2024,
	title = {Kubernetes Deployment Options for On-Prem Clusters},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2407.01620},
	doi = {10.48550/ARXIV.2407.01620},
	abstract = {Over the last decade, the Kubernetes container orchestration platform has become essential to many scientific workflows. Despite its popularity, deploying a production-ready Kubernetes cluster on-premises can be challenging for system administrators. Many of the proprietary integrations that application developers take for granted in commercial cloud environments must be replaced with alternatives when deployed locally. This article will compare three popular deployment strategies for sites deploying Kubernetes on-premise: Kubeadm with Kubespray, {OpenShift} / {OKD} and Rancher via K3S/{RKE}2.},
	publisher = {{arXiv}},
	author = {Bryant, Lincoln and Gardner, Robert W. and Hu, Fengping and Jordan, David and Taylor, Ryan P.},
	urldate = {2024-10-04},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Computational Physics (physics.comp-ph), Distributed, Parallel, and Cluster Computing (cs.{DC}), {FOS}: Computer and information sciences, {FOS}: Physical sciences},
}

@inproceedings{joy_performance_2015,
	title = {Performance comparison between Linux containers and virtual machines},
	url = {https://ieeexplore.ieee.org/abstract/document/7164727?casa_token=hUkLzXuINLMAAAAA:GYX9uQnlz_JagpyCL5Ow2IAmDXKB7ktEM3u-xWlkS0ABUFzFLII9k2fIWg4qq9EJjcJEkVbiqw},
	doi = {10.1109/ICACEA.2015.7164727},
	abstract = {With the advent of cloud computing and virtualization, modern distributed applications run on virtualized environments for hardware resource utilization and flexibility of operations in an infrastructure. However, when it comes to virtualization, resource overhead is involved. Linux containers can be an alternative to traditional virtualization technologies because of its high resource utilization and less overhead. This paper provides a comparison between Linux containers and virtual machines in terms of performance and scalability.},
	eventtitle = {2015 International Conference on Advances in Computer Engineering and Applications},
	pages = {342--346},
	booktitle = {2015 International Conference on Advances in Computer Engineering and Applications},
	author = {Joy, Ann Mary},
	urldate = {2024-10-04},
	date = {2015-03},
	keywords = {Containers, Linux, Scalability, Servers, Virtual machine monitors, Virtual machining, Virtualization, cloud computing, containers, docker, hypervisor, kubernetes, virtualization},
}

@inproceedings{spoiala_performance_2016,
	title = {Performance comparison of a {WebRTC} server on Docker versus virtual machine},
	url = {https://ieeexplore.ieee.org/abstract/document/7492590?casa_token=QBY7Qj-3SVoAAAAA:9_alIK4iQlSUzbIbQ6lHWUY8UsG9GcAxWYMsgq19OlHq0604g86tSO4zQDAV-wGZMzXMU0d9dw},
	doi = {10.1109/DAAS.2016.7492590},
	abstract = {Current developments in real-time technologies enable multiple companies to focus on a standard in order to bring real-time technologies to the web. The efforts lead to the {API} standard {WebRTC} that supports voice and video chat and P2P file sharing, without the need to install external plugins on browsers. As lots of services will switch to {WebRTC} we found useful to provide a comparison of a {WebRTC} server on Docker containers and virtual machines. As {WebRTC} server, we used Kurento Media Server, a powerful open source server with many advanced features. This paper is testing what kind of virtualization is more suitable for a multimedia application based on {WebRTC}. We tested Docker containers and {KVM} machines with a multimedia based test. As lots of services will switch to {WebRTC} we found useful to provide a comparison between two kinds of virtualization for a multimedia application based on {WebRTC}. Thus, we considered a {WebRTC} server on Docker containers and virtual machines. As {WebRTC} server, we used Kurento Media Server, a powerful open source server with many advanced features. We tested the Docker containers and {KVM} machines with a multimedia based test.},
	eventtitle = {2016 International Conference on Development and Application Systems ({DAS})},
	pages = {295--298},
	booktitle = {2016 International Conference on Development and Application Systems ({DAS})},
	author = {Spoiala, Cristian Constantin and Calinciuc, Alin and Turcu, Corneliu Octavian and Filote, Constantin},
	urldate = {2024-10-04},
	date = {2016-05},
	keywords = {Computer performance, Containers, Media, Multimedia communication, Open source software, Operating systems, Real-time systems, Servers, Virtual machine monitors, Virtual machining, {WebRTC}},
}

@inproceedings{salah_performance_2017,
	title = {Performance comparison between container-based and {VM}-based services},
	url = {https://ieeexplore.ieee.org/abstract/document/7899408?casa_token=aKu5ivTH968AAAAA:Ph0vt3NfPpu7ET_j4w_6vgrDVWsCeJl3jv7saEM9vjxNA14qAVkciNGU2OAWHbbYdDU9qCVC6A},
	doi = {10.1109/ICIN.2017.7899408},
	abstract = {These days, microservice architecture is widely used in the design and development of many real-time, critical, and large-scale online services. These services are typically deployed using Docker containers on cloud platforms. Container technology supports the deployment of these services with high portability, scalability, and performance, when compared to deploying them using virtual machines (i.e. {VM}-based services). It is widely known fact that container-based services give better performance than {VM}-based services. However, we show in this paper that services deployed using Amazon {AWS} {ECS} ({EC}2 Container Service) surprisingly perform significantly worse when compared with services deployed using Amazon {EC}2 {VMs}. We study and quantify the performance difference in terms of throughput, response time and {CPU} utilization considering different deployment scenarios.},
	eventtitle = {2017 20th Conference on Innovations in Clouds, Internet and Networks ({ICIN})},
	pages = {185--190},
	booktitle = {2017 20th Conference on Innovations in Clouds, Internet and Networks ({ICIN})},
	author = {Salah, Tasneem and Zemerly, M. Jamal and Yeun, Chan Yeob and Al-Qutayri, Mahmoud and Al-Hammadi, Yousof},
	urldate = {2024-10-04},
	date = {2017-03},
	note = {{ISSN}: 2472-8144},
	keywords = {Cloud computing, Computer architecture, Containers, Docker containers, Microservices, Performance Evaluation, Servers, Throughput, Virtual Machines, Virtual machining},
}

@inproceedings{sharma_containers_2016,
	location = {New York, {NY}, {USA}},
	title = {Containers and Virtual Machines at Scale: A Comparative Study},
	isbn = {978-1-4503-4300-8},
	url = {https://dl.acm.org/doi/10.1145/2988336.2988337},
	doi = {10.1145/2988336.2988337},
	series = {Middleware '16},
	shorttitle = {Containers and Virtual Machines at Scale},
	abstract = {Virtualization is used in data center and cloud environments to decouple applications from the hardware they run on. Hardware virtualization and operating system level virtualization are two prominent technologies that enable this. Containers, which use {OS} virtualization, have recently surged in interest and deployment. In this paper, we study the differences between the two virtualization technologies. We compare containers and virtual machines in large data center environments along the dimensions of performance, manageability and software development.We evaluate the performance differences caused by the different virtualization technologies in data center environments where multiple applications are running on the same servers (multi-tenancy). Our results show that co-located applications can cause performance interference, and the degree of interference is higher in the case of containers for certain types of workloads. We also evaluate differences in the management frameworks which control deployment and orchestration of containers and {VMs}. We show how the different capabilities exposed by the two virtualization technologies can affect the management and development of applications. Lastly, we evaluate novel approaches which combine hardware and {OS} virtualization.},
	pages = {1--13},
	booktitle = {Proceedings of the 17th International Middleware Conference},
	publisher = {Association for Computing Machinery},
	author = {Sharma, Prateek and Chaufournier, Lucas and Shenoy, Prashant and Tay, Y. C.},
	urldate = {2024-10-03},
	date = {2016-11-28},
}

@inproceedings{gil_cloud_2021,
	title = {Cloud Native Computing for Industry 4.0: Challenges and Opportunities},
	url = {https://ieeexplore.ieee.org/abstract/document/9613386?casa_token=9Sgnayyvkw4AAAAA:mZZYkS5Vsm32Lon71jZihzTsv82-eSTXefd47lngFRijrNC_A_8CjhK8qEsrCvOXEA08WqXeRQ},
	doi = {10.1109/ETFA45728.2021.9613386},
	shorttitle = {Cloud Native Computing for Industry 4.0},
	abstract = {Cloud-based architectures are advantageous in aspects such as scalability, reliability and resource utilization efficiency, to name just a few, thus being considered one of the pillars of Industry 4.0. However, in this domain, cloud computing platforms are subject to specific requirements, namely in what concerns real-time performance, determinism and fault-tolerance. This paper focuses on cloud native computing, which is an emerging and promising cloud-computing paradigm, specifically addressing its applicability to real-time systems. Firstly, it introduces the architecture of cloud native applications, discussing their principles, potential advantages and challenges. Then it addresses the opportunities and constraints of such technologies when applied to industrial real-time systems.},
	eventtitle = {2021 26th {IEEE} International Conference on Emerging Technologies and Factory Automation ({ETFA} )},
	pages = {01--04},
	booktitle = {2021 26th {IEEE} International Conference on Emerging Technologies and Factory Automation ({ETFA} )},
	author = {Gil, Guilherme and Corujo, Daniel and Pedreiras, Paulo},
	urldate = {2024-10-04},
	date = {2021-09},
	keywords = {Cloud computing, Cloud native, Computer architecture, Industrial Informatics, Maintenance engineering, Processor scheduling, Quality-of-Service, Real-time systems, Scalability, Scheduling, Solids},
}

@thesis{cicchiello_analysis_2021,
	title = {Analysis, modeling and implementation of cost models for a multi-cloud Kubernetes context},
	rights = {cc\_by\_nc\_nd},
	url = {https://webthesis.biblio.polito.it/21146/},
	abstract = {In the last years cloud computing is becoming more and more important for companies. They start developing their applications to be cloud-native, composed by a bunch of containerized micro-services cooperating each other in order to exploit the horizontal scalability capabilities. Having many containers require a component able to manage their life cycle: the widely used solution is Kubernetes.  More and more companies are interested in diversifying their cloud infrastructure in two main ways: multi-cloud, that is having clusters at different public cloud providers, or hybrid cloud, an owned physical data center and a virtual infrastructure at one or more cloud providers. Diversifying the infrastructure allows to increase resiliency, to be present on different geographical regions, to avoid lock-in to a single provider and gives the opportunity of saving costs.  The last point is what this thesis wants to investigate. How can we exploit that kind of infrastructures optimizing costs?  Public cloud clusters are elastic: the number of nodes can increase and decrease in time to adapt their overall capacity to the actual workload in execution. This has to be kept into consideration when modeling their costs.  Knowing how Kubernetes cluster costs are structured can be very useful for many reasons: for teams to increase awareness on how much are spending, to compare what cloud provider is more convenient for some requirements, to estimate the costs of having a private datacenter and comparing it to having virtual infrastructures.  Cloud providers bills, unfortunately, does not give at all details on how costs are distributed, so having a model can make them more clear.  An effort has been made on modeling container costs since they are the smallest execution unit in Kubernetes. Two kind of models have been defined: the overall Kubernetes cluster cost model (one for the public cloud, one for the private cloud) and the container cost model.  The knowledge of the container cost model has been then applied to a multi-cluster scheduling scenario to increase the cost efficiency of the container distribution among the clusters thanks to their cost information.},
	pagetotal = {72},
	institution = {Politecnico di Torino},
	type = {laurea},
	author = {Cicchiello, Federico},
	urldate = {2024-10-03},
	date = {2021-12-17},
	langid = {italian},
}

@inproceedings{li_cloudcmp_2010,
	location = {New York, {NY}, {USA}},
	title = {{CloudCmp}: comparing public cloud providers},
	isbn = {978-1-4503-0483-2},
	url = {https://dl.acm.org/doi/10.1145/1879141.1879143},
	doi = {10.1145/1879141.1879143},
	series = {{IMC} '10},
	shorttitle = {{CloudCmp}},
	abstract = {While many public cloud providers offer pay-as-you-go computing, their varying approaches to infrastructure, virtualization, and software services lead to a problem of plenty. To help customers pick a cloud that fits their needs, we develop {CloudCmp}, a systematic comparator of the performance and cost of cloud providers. {CloudCmp} measures the elastic computing, persistent storage, and networking services offered by a cloud along metrics that directly reflect their impact on the performance of customer applications. {CloudCmp} strives to ensure fairness, representativeness, and compliance of these measurements while limiting measurement cost. Applying {CloudCmp} to four cloud providers that together account for most of the cloud customers today, we find that their offered services vary widely in performance and costs, underscoring the need for thoughtful provider selection. From case studies on three representative cloud applications, we show that {CloudCmp} can guide customers in selecting the best-performing provider for their applications.},
	pages = {1--14},
	booktitle = {Proceedings of the 10th {ACM} {SIGCOMM} conference on Internet measurement},
	publisher = {Association for Computing Machinery},
	author = {Li, Ang and Yang, Xiaowei and Kandula, Srikanth and Zhang, Ming},
	urldate = {2024-10-03},
	date = {2010-11-01},
}

@online{noauthor_argo_nodate,
	title = {Argo {CD} - Declarative {GitOps} {CD} for Kubernetes},
	url = {https://argo-cd.readthedocs.io/en/stable/},
	urldate = {2024-09-29},
}

@online{noauthor_helm_nodate,
	title = {Helm},
	url = {https://helm.sh/},
	abstract = {Helm - The Kubernetes Package Manager.},
	urldate = {2024-09-29},
	langid = {english},
}

@online{noauthor_vmware_nodate,
	title = {{VMware} Tanzu Platform},
	url = {https://tanzu.vmware.com/platform},
	abstract = {{VMware} Tanzu is a cloud native application platform that enables vital {DevSecOps} outcomes in a multi-cloud world.},
	urldate = {2024-09-29},
}

@thesis{bruno_automation_2024,
	title = {Automation and provisioning of Kubernetes on bare-metal telco edge infrastructures},
	rights = {cc\_by\_nc\_sa},
	url = {https://webthesis.biblio.polito.it/31755/},
	abstract = {Cloud computing has revolutionized the deployment of innovative services, with cloud-native applications becoming a fundamental design pattern. Kubernetes has emerged as the leading platform for container and application management in this paradigm. For telecommunication companies (Telcos) with numerous edge sites, adopting cloud-native solutions offers the potential for rapid deployment, configuration, and maintenance of network applications, while ensuring a robust certification process.    However, this shift requires a certified, modular, and extensible framework to manage multiple edge sites along with their associated Network Functions and services. The Sylva Project aims to provide such a framework, offering a reference implementation based on open-source software tailored to European Telcos' needs. Sylva seeks to automate and standardize the traditionally manual and fragmented process of deploying and managing edge sites with bare-metal or virtualized nodes.    The automation of bare-metal Sylva deployments presents a unique challenge, requiring deep, domain-specific knowledge of the underlying infrastructure. This thesis proposes an architecture based on the Server Operator and its related Custom Resource Definitions ({CRDs}).    An important component of this solution is to seamlessly integrate within the existing stack, while following the patterns and standards of Kubernetes and the tools used within Sylva. This is achieved by extending Sylva's current operators to simplify the configuration of bare-metal nodes. By doing so, the proposed architecture aims to enhance collaboration between infrastructure administrators and application developers, ultimately increasing deployment agility in Telco environments.},
	pagetotal = {51},
	institution = {Politecnico di Torino},
	type = {laurea},
	author = {Bruno, Francesco},
	urldate = {2024-09-29},
	date = {2024-07-26},
	langid = {italian},
}

@inproceedings{ascensao_assessing_2024,
	title = {Assessing Kubernetes Distributions: A Comparative Study},
	url = {https://ieeexplore.ieee.org/abstract/document/10608706},
	doi = {10.1109/MELECON56669.2024.10608706},
	shorttitle = {Assessing Kubernetes Distributions},
	abstract = {Kubernetes is now the most widely used container orchestration tool in the Cloud. However, when deploying Kubernetes clusters in resource-constrained environments such as the Cloud-to-Edge continuum, new challenges arise. To address this issue, lightweight distributions of Kubernetes have been developed. It is crucial to fully understand the performance and security levels of the Kubernetes solution to deploy, as these factors could impact the services and applications running in the cluster. This research compares the performance and security of three Kubernetes distributions: K8s, K3s and K0s. Results indicated K3s lacks in performance due to scalability issues compared to K0s (top performer) and K8s. Moreover, the latter two exhibit fewer security vulnerabilities.},
	eventtitle = {2024 {IEEE} 22nd Mediterranean Electrotechnical Conference ({MELECON})},
	pages = {832--837},
	booktitle = {2024 {IEEE} 22nd Mediterranean Electrotechnical Conference ({MELECON})},
	author = {Ascensão, Pedro and Neto, Luís Filipe and Velasquez, Karima and Abreu, David Perez},
	urldate = {2024-09-29},
	date = {2024-06},
	note = {{ISSN}: 2158-8481},
	keywords = {Cloud, Containers, Edge, Kubernetes, Scalability, Security, benchmark, performance, security},
}

@online{portworx_kubernetes_2021,
	title = {Kubernetes Adoption Survey 2021},
	url = {https://investor.purestorage.com/news-and-events/press-releases/press-release-details/2021/New-Survey-Finds-Enterprise-IT-Users-Doubled-Down-on-Kubernetes-to-Support-Rapid-Pivots-in-Business-Amid-Pandemic/default.aspx},
	abstract = {New data from Portworx by Pure Storage underscores the unique value Kubernetes provides to businesses and {IT} teams everywhere Portworx ® by Pure Storage ® ({NYSE}: {PSTG}), the most complete Kubernetes Data Services Platform, today released findings from its annual Kubernetes Adoption Survey 1 . The survey assesses the mass adoption and evolution of Kubernetes usage among enterprise users in the last 12 months, in addition to the impact of the pandemic on {IT} users' attitudes towards their jobs. Supported by an overwhelming response from {IT} users, the findings suggest that despite budget cuts, enterprises are rapidly turning to Kubernetes to drive faster business results and, overall, reported happier, well-paid {IT} employees. For over a year, the pandemic has challenged businesses everywhere to experiment and innovate their offerings to cater to evolving customer demands for convenience and simplicity, as well as supporting employees in the new world of remote work. In the midst of it},
	author = {{Portworx}},
	urldate = {2024-09-29},
	date = {2021},
	langid = {american},
}

@online{broadcom_state_2023,
	title = {The State of Kubernetes 2023},
	url = {https://go-vmware.broadcom.com/reg-the-state-of-kubernetes},
	author = {{Broadcom}},
	urldate = {2024-09-29},
	date = {2023},
}

@online{portworx_voice_2024,
	title = {The Voice of Kubernetes Experts Report 2024},
	url = {https://portworx.com/resources/voice-of-kubernetes-expert-report/},
	abstract = {Learn the top trends for Kubernetes experts across persistent storage and virtualization as they prepare for a cloud native future.},
	titleaddon = {Portworx},
	author = {{Portworx}},
	urldate = {2024-09-29},
	date = {2024},
	langid = {american},
}

@online{red_hat_inc_state_2024,
	title = {The state of Kubernetes security report: 2024 edition},
	url = {https://www.redhat.com/en/engage/state-kubernetes-security-report-2024},
	shorttitle = {The state of Kubernetes security report},
	abstract = {Read about new, emerging trends in container, Kubernetes, and cloud-native security in this latest edition of the State of Kubernetes security report.},
	author = {{Red Hat Inc.}},
	urldate = {2024-09-29},
	date = {2024},
	langid = {english},
}

@online{putz_kubernetes_2023,
	title = {Kubernetes in the wild report 2023},
	url = {https://www.dynatrace.com/news/blog/kubernetes-in-the-wild-2023/},
	abstract = {The Kubernetes in the Wild survey shows how organizations use Kubernetes and related technologies in production as K8s adoption expands.},
	titleaddon = {Dynatrace news},
	author = {Putz, Peter, Alois Mayr},
	urldate = {2024-09-29},
	date = {2023-01-16},
	langid = {american},
}

@article{lunden_isolating_nodate,
	title = {Isolating low latency traffic in a network and lowering queuing latency using L4S},
	abstract = {Reliable and low latency networks allow safe and efficient automation and remote control of vehicles. However, when typical networks become congested, low latency can not be guaranteed. This limits, for example, the efficiency of remote controlling of vehicles and other latency-sensitive applications such as autonomous cars using {IP} networks.},
	author = {Lundén, Jaakko-Juhani},
	langid = {english},
}

@online{noauthor_gke_nodate,
	title = {{GKE} overview {\textbar} Google Kubernetes Engine ({GKE})},
	url = {https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview},
	abstract = {Google Kubernetes Engine ({GKE}) is a managed Kubernetes service for deploying containerized applications on Google Cloud.},
	titleaddon = {Google Cloud},
	urldate = {2024-09-15},
	langid = {english},
}

@online{noauthor_managed_nodate,
	title = {Managed Kubernetes Service ({AKS}) {\textbar} Microsoft Azure},
	url = {https://azure.microsoft.com/en-us/products/kubernetes-service},
	abstract = {Azure Kubernetes Service ({AKS}) is a managed Kubernetes service with hardened security and fast delivery. Deploy and manage containerized applications with {AKS}.},
	urldate = {2024-09-15},
	langid = {american},
}

@online{nickomang_azure_nodate,
	title = {Azure Kubernetes Service ({AKS}) documentation},
	url = {https://learn.microsoft.com/en-us/azure/aks/},
	abstract = {{AKS} allows you to quickly deploy a production ready Kubernetes cluster in Azure. Learn how to use {AKS} with these quickstarts, tutorials, and samples.},
	author = {Nickomang},
	urldate = {2024-09-15},
	langid = {english},
}

@online{noauthor_amazon_nodate,
	title = {Amazon {EKS} Customers {\textbar} Managed Kubernetes Service {\textbar} Amazon Web Services},
	url = {https://aws.amazon.com/eks/},
	abstract = {Learn how customers run Kubernetes on Amazon {EKS} with detailed case studies and videos.},
	titleaddon = {Amazon Web Services, Inc.},
	urldate = {2024-09-15},
	langid = {american},
}

@online{noauthor_assessing_nodate,
	title = {Assessing Kubernetes Distributions: A Comparative Study},
	url = {https://ieeexplore.ieee.org/abstract/document/10608706?casa_token=aZACTapbLW8AAAAA:mniRvQHWIVfdh-QIyHhlJGG5UX1FwHRMGDeTP7YiqfTELF3A4Hu8iSJ-6wjwsSUPa6oL8IVcqA},
	shorttitle = {Assessing Kubernetes Distributions},
	abstract = {Kubernetes is now the most widely used container orchestration tool in the Cloud. However, when deploying Kubernetes clusters in resource-constrained environments such as the Cloud-to-Edge continuum, new challenges arise. To address this issue, lightweight distributions of Kubernetes have been developed. It is crucial to fully understand the performance and security levels of the Kubernetes solution to deploy, as these factors could impact the services and applications running in the cluster. This research compares the performance and security of three Kubernetes distributions: K8s, K3s and K0s. Results indicated K3s lacks in performance due to scalability issues compared to K0s (top performer) and K8s. Moreover, the latter two exhibit fewer security vulnerabilities.},
	urldate = {2024-09-15},
	langid = {american},
}

@article{kjorveziroski_kubernetes_2022,
	title = {Kubernetes distributions for the edge: serverless performance evaluation},
	volume = {78},
	issn = {1573-0484},
	url = {https://doi.org/10.1007/s11227-022-04430-6},
	doi = {10.1007/s11227-022-04430-6},
	shorttitle = {Kubernetes distributions for the edge},
	abstract = {Serverless computing, especially when deployed at the edge of the network, is seen as an enabling technology for the future development of more complex Internet of Things systems. However, special care must be taken when deploying new edge infrastructures for serverless workloads in terms of resource usage and network connectivity. Inefficient utilization of the available computing resources might easily cancel out the benefits acquired by moving the equipment closer to the edge, namely the reduced communication latency. Containers, together with the Kubernetes container orchestrator, are used by many serverless platforms today. We evaluate the performance of three different Kubernetes distributions—full-fledged Kubernetes, K3s, and {MicroK}8s when deployed in a resource constrained environment at the edge. We use the {OpenFaaS} serverless platform and employ 14 different benchmarks divided into three separate categories to evaluate various aspects of the execution performance of the distributions. Four different test types are performed focusing on cold start latency, serial execution performance, parallel execution using a single replica, and parallel execution utilizing different autoscaling strategies. Our results show that the edge-oriented K3s and {MicroK}8s distributions offer better performance in the majority of the tests, while a full-fledged deployment exhibits noticeable advantages for sustained loads such as parallel function invocation using a single replica.},
	pages = {13728--13755},
	number = {11},
	journaltitle = {The Journal of Supercomputing},
	shortjournal = {J Supercomput},
	author = {Kjorveziroski, Vojdan and Filiposka, Sonja},
	urldate = {2024-09-15},
	date = {2022-07-01},
	langid = {english},
	keywords = {Artificial Intelligence, Function as a service, Internet of Things, Kubernetes, Performance evaluation, Serverless computing},
}

@online{noauthor_how_nodate,
	title = {How Kubernetes came to be: A co-founder shares the story},
	url = {https://cloud.google.com/blog/products/containers-kubernetes/from-google-to-the-world-the-kubernetes-origin-story},
	shorttitle = {How Kubernetes came to be},
	abstract = {Google Cloud is the birthplace of Kubernetes—originally developed at Google and released as open source in 2014. Learn the Kubernetes origin story.},
	titleaddon = {Google Cloud Blog},
	urldate = {2024-09-15},
	langid = {american},
}

@article{bhardwaj_virtualization_2021,
	title = {Virtualization in Cloud Computing: Moving from Hypervisor to Containerization—A Survey},
	volume = {46},
	issn = {2191-4281},
	url = {https://doi.org/10.1007/s13369-021-05553-3},
	doi = {10.1007/s13369-021-05553-3},
	shorttitle = {Virtualization in Cloud Computing},
	abstract = {Containers emerged as a lightweight alternative to virtual machines that offer better microservice architecture support. They are widely used by organizations to deploy their increasingly diverse workloads derived from modern applications such as big data, {IoT}, and edge/fog computing in either proprietary clusters or private, public cloud data centers. With the growing interest in container-based virtualization technologies, the requirement to explore the deployment and orchestration of clusters of containers has become a central research problem. Although progress has been made to study containerization, systematic consolidation of the existing literature with a summative evaluation is still missing. To fill this gap, in this paper, we first taxonomically classify the existing research studies on the performance comparison between hypervisor and container technology and then analyze state-of-the-art for container cluster management orchestration systems, its performance monitoring tools, and finally future research trends. This results in a better understanding of container technology with attention to provide summative analysis in terms of (i) how much performance overhead is generated by a hypervisor compared to container-based virtualization, (ii) which container technology is suited for a cloud application deployment based on the type of benchmark executing, (iii) how to provide management of containers deployed in a cluster environment, (iv) container performance monitoring tools, and (v) finally emerging concerns for future research directions.},
	pages = {8585--8601},
	number = {9},
	journaltitle = {Arabian Journal for Science and Engineering},
	shortjournal = {Arab J Sci Eng},
	author = {Bhardwaj, Aditya and Krishna, C. Rama},
	urldate = {2024-09-15},
	date = {2021-09-01},
	langid = {english},
	keywords = {Artificial Intelligence, Cloud computing, Containerization, Hypervisor, Virtualization},
}

@inproceedings{zhang_cloud_2022,
	title = {Cloud native technology development trend analysis research},
	volume = {12350},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12350/123501E/Cloud-native-technology-development-trend-analysis-research/10.1117/12.2652770.full},
	doi = {10.1117/12.2652770},
	abstract = {With the rapid development of virtualization, cloud computing and other technologies, and their gradual application in various industries, how to use the cloud computing infrastructure well and make the cloud computing play the maximum capacity is an important issue in cloud computing technology. In this context, the concept of "cloud-native" was born. With the development of cloud-native technology, its related research has gradually become a field of concern and research for scholars, but there is still a lack of research on the development trend of cloud-native technology. Therefore, in this paper, 904 high-quality papers were downloaded from web of science and correlation analysis was conducted by Citespace and {VOSviewer} with the help of bibliometric research methods, including literature quantity analysis, co-citation analysis, keyword co-occurrence analysis and research hotspot analysis.},
	eventtitle = {6th International Workshop on Advanced Algorithms and Control Engineering ({IWAACE} 2022)},
	pages = {345--350},
	booktitle = {6th International Workshop on Advanced Algorithms and Control Engineering ({IWAACE} 2022)},
	publisher = {{SPIE}},
	author = {Zhang, Yuxiang and Han, Jiujiang and Liu, Jian and Xian, Ming and Wang, Huimei and Chen, Yu and Zhang, Renfei and Zhang, Lei},
	urldate = {2024-09-15},
	date = {2022-10-20},
}

@article{gannon_cloud-native_2017,
	title = {Cloud-Native Applications},
	volume = {4},
	issn = {2325-6095},
	url = {https://ieeexplore.ieee.org/abstract/document/8125550},
	doi = {10.1109/MCC.2017.4250939},
	abstract = {Cloud-native is a term that is invoked often but seldom defined beyond saying “we built it in the cloud” as opposed to “on-prem”. However, there is now an emerging consensus around key ideas and informal applications design patterns that have been adopted and used in many successful cloud applications. In this introduction, we will describe these cloud-native concepts and illustrate them with examples. We will also look at the technical trends that may give us an idea about the future of cloud applications. We begin by discussing the basic properties that many cloud-native apps have in common. Once we have characterized them, we can then describe how these properties emerge from the technical design patterns.},
	pages = {16--21},
	number = {5},
	journaltitle = {{IEEE} Cloud Computing},
	author = {Gannon, Dennis and Barga, Roger and Sundaresan, Neel},
	urldate = {2024-09-13},
	date = {2017-09},
	note = {Conference Name: {IEEE} Cloud Computing},
	keywords = {cloud computing, cloud-native, distributed computing, microservices, serverless},
}

@article{kratzke_understanding_2017,
	title = {Understanding cloud-native applications after 10 years of cloud computing - A systematic mapping study},
	volume = {126},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217300018},
	doi = {10.1016/j.jss.2017.01.001},
	abstract = {It is common sense that cloud-native applications ({CNA}) are intentionally designed for the cloud. Although this understanding can be broadly used it does not guide and explain what a cloud-native application exactly is. The term “cloud-native” was used quite frequently in birthday times of cloud computing (2006) which seems somehow obvious nowadays. But the term disappeared almost completely. Suddenly and in the last years the term is used again more and more frequently and shows increasing momentum. This paper summarizes the outcomes of a systematic mapping study analyzing research papers covering “cloud-native” topics, research questions and engineering methodologies. We summarize research focuses and trends dealing with cloud-native application engineering approaches. Furthermore, we provide a definition for the term “cloud-native application” which takes all findings, insights of analyzed publications and already existing and well-defined terminology into account.},
	pages = {1--16},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Kratzke, Nane and Quint, Peter-Christian},
	urldate = {2024-09-13},
	date = {2017-04-01},
	keywords = {{CNA}, Cloud-native application, Elastic platform, Microservice, Pattern, Self service, Softwareization, Systematic mapping study},
}

@inproceedings{pereira_ferreira_performance_2019,
	title = {A Performance Evaluation of Containers Running on Managed Kubernetes Services},
	url = {https://ieeexplore.ieee.org/document/8968907},
	doi = {10.1109/CloudCom.2019.00038},
	abstract = {Container-based virtualisation technologies are gaining more and more traction in recent years across Cloud platforms and this will likely continue in the coming years. As such, containers orchestration technologies are becoming indispensable. Kubernetes has become the de facto standard because of its robustness, maturity and rich features. To free users of the burden of having to configure and maintain complex Kubernetes infrastructures, but still make use of its functionalities, all major Cloud providers are now offering cloud-native managed Kubernetes alternatives. The goal of this paper is to investigate the performance of containers running in such hosted services. For this purpose, we conduct a series of experimental evaluations of containers to monitor the behaviour of system resources including {CPU}, memory, disk and network. A baseline consisting of a manually deployed Kubernetes cluster was built for comparison. In particular, we consider the Amazon Elastic Container Service for Kubernetes ({EKS}), Microsoft Azure Kubernetes Service ({AKS}) and Google Kubernetes Engine ({GKE}). The Australia-wide {NeCTAR} Research Cloud was used for the baseline.},
	eventtitle = {2019 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	pages = {199--208},
	booktitle = {2019 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	author = {Pereira Ferreira, Arnaldo and Sinnott, Richard},
	urldate = {2024-09-12},
	date = {2019-12},
	note = {{ISSN}: 2330-2186},
	keywords = {{AKS}, Benchmarking, Containers, {EKS}, {GKE}, Kubernetes, Orchestration, Performance Evaluation},
}

@inproceedings{tamiru_experimental_2020,
	title = {An Experimental Evaluation of the Kubernetes Cluster Autoscaler in the Cloud},
	url = {https://ieeexplore.ieee.org/document/9407312},
	doi = {10.1109/CloudCom49646.2020.00002},
	abstract = {Despite the abundant research in cloud autoscaling, autoscaling in Kubernetes, arguably the most popular cloud platform today, is largely unexplored. Kubernetes' Cluster Autoscaler can be configured to select nodes either from a single node pool ({CA}) or from multiple node pools ({CA}-{NAP}). We evaluate and compare these configurations using two representative applications and workloads on Google Kubernetes Engine ({GKE}). We report our results using monetary cost and standard autoscaling performance metrics (under- and over-provisioning accuracy, under- and over-provisioning timeshare, instability of elasticity and deviation from the theoretical optimal autoscaler) endorsed by the {SPEC} Cloud Group. We show that, overall, {CA}-{NAP} outperforms {CA} and that autoscaling performance depends mainly on the composition of the workload. We compare our results with those of the related work and point out further configuration tuning opportunities to improve performance and cost-saving.},
	eventtitle = {2020 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	pages = {17--24},
	booktitle = {2020 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	author = {Tamiru, Mulugeta Ayalew and Tordsson, Johan and Elmroth, Erik and Pierre, Guillaume},
	urldate = {2024-09-12},
	date = {2020-12},
	note = {{ISSN}: 2330-2186},
	keywords = {Cloud computing, Computers, Conferences, Containers, Elasticity, Kubernetes, Measurement, Task analysis, autoscaling},
}

@inproceedings{courageux-sudan_automated_2021,
	title = {Automated performance prediction of microservice applications using simulation},
	url = {https://ieeexplore.ieee.org/document/9614260},
	doi = {10.1109/MASCOTS53633.2021.9614260},
	abstract = {Microservices transform monolithic applications into simple, scalable, and interacting services. It allows for faster development and fine-grained deployments. However, the cooperation of several services leads to intricate dependencies, hindering the detection of performance bottlenecks. Current microservice performance analysis methods require real deployments, a costly process both in time and resources, while performance prediction through simulation relies on models that are complex to develop and instantiate. In this paper, we propose a microservice performance analysis approach based on simulation. Our contribution first introduces a microservice performance model requiring few instantiation parameters. We then propose a methodology to automatically derive model instantiation values from a single execution trace. We evaluate this methodology on two benchmarks from the literature. Our approach accurately predicts the deployment performance of large-scale microservice applications in various configurations from a single execution trace. This provides valuable insights on the performance of an application prior to its deployment on real platform.},
	eventtitle = {2021 29th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	pages = {1--8},
	booktitle = {2021 29th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	author = {Courageux-Sudan, Clément and Orgerie, Anne-Cécile and Quinson, Martin},
	urldate = {2024-08-23},
	date = {2021-11},
	note = {{ISSN}: 2375-0227},
	keywords = {Analytical models, Benchmark testing, Computational modeling, Microservice, Modeling and simulation, Performance evaluation, Predictive models, Transforms, Web services},
}

@article{khan_perfsim_2023,
	title = {{PerfSim}: A Performance Simulator for Cloud Native Microservice Chains},
	volume = {11},
	issn = {2168-7161, 2372-0018},
	url = {http://arxiv.org/abs/2103.08983},
	doi = {10.1109/TCC.2021.3135757},
	shorttitle = {{PerfSim}},
	abstract = {Cloud native computing paradigm allows microservice-based applications to take advantage of cloud infrastructure in a scalable, reusable, and interoperable way. However, in a cloud native system, the vast number of configuration parameters and highly granular resource allocation policies can significantly impact the performance and deployment cost. For understanding and analyzing these implications in an easy, quick, and cost-effective way, we present {PerfSim}, a discrete-event simulator for approximating and predicting the performance of cloud native service chains in user-defined scenarios. To this end, we proposed a systematic approach for modeling the performance of microservices endpoint functions by collecting and analyzing their performance and network traces. With a combination of the extracted models and user-defined scenarios, {PerfSim} can then simulate the performance behavior of all services over a given period and provide an approximation for system {KPIs}, such as requests' average response time. Using the processing power of a single laptop, we evaluated both simulation accuracy and speed of {PerfSim} in 104 prevalent scenarios and compared the simulation results with the identical deployment in a real Kubernetes cluster. We achieved {\textasciitilde}81-99\% simulation accuracy in approximating the average response time of incoming requests and {\textasciitilde}16-1200 times speed-up factor for the simulation.},
	pages = {1395--1413},
	number = {2},
	journaltitle = {{IEEE} Transactions on Cloud Computing},
	shortjournal = {{IEEE} Trans. Cloud Comput.},
	author = {Khan, Michel Gokan and Taheri, Javid and Al-Dulaimy, Auday and Kassler, Andreas},
	urldate = {2024-08-23},
	date = {2023-04-01},
	eprinttype = {arxiv},
	eprint = {2103.08983 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance},
}

@article{ketzler_digital_2020,
	title = {Digital Twins for Cities: A State of the Art Review},
	url = {https://www-ingentaconnect-com.libproxy.aalto.fi/content/alex/benv/2020/00000046/00000004/art00004#},
	shorttitle = {Digital Twins for Cities},
	author = {Ketzler, Bernd and Naserentin, Vasilis and Latino, Fabio and Zangelidis, Christopher and Thuvander, Liane and Logg, Anders},
	urldate = {2024-01-10},
	date = {2020},
	langid = {english},
}

@online{noauthor_about_nodate,
	title = {About {OpenShift} Virtualization - About {\textbar} Virtualization {\textbar} {OpenShift} Container Platform 4.15},
	url = {https://docs.openshift.com/container-platform/4.15/virt/about_virt/about-virt.html},
	urldate = {2024-06-16},
}

@online{noauthor_5g_nodate,
	title = {5G System Overview},
	url = {https://www.3gpp.org/technologies/5g-system-overview},
	urldate = {2024-05-24},
}

@article{shafi_5g_2017,
	title = {5G: A Tutorial Overview of Standards, Trials, Challenges, Deployment, and Practice},
	volume = {35},
	issn = {1558-0008},
	url = {https://ieeexplore.ieee.org/document/7894280},
	doi = {10.1109/JSAC.2017.2692307},
	shorttitle = {5G},
	abstract = {There is considerable pressure to define the key requirements of 5G, develop 5G standards, and perform technology trials as quickly as possible. Normally, these activities are best done in series but there is a desire to complete these tasks in parallel so that commercial deployments of 5G can begin by 2020. 5G will not be an incremental improvement over its predecessors; it aims to be a revolutionary leap forward in terms of data rates, latency, massive connectivity, network reliability, and energy efficiency. These capabilities are targeted at realizing high-speed connectivity, the Internet of Things, augmented virtual reality, the tactile internet, and so on. The requirements of 5G are expected to be met by new spectrum in the microwave bands (3.3-4.2 {GHz}), and utilizing large bandwidths available in mm-wave bands, increasing spatial degrees of freedom via large antenna arrays and 3-D {MIMO}, network densification, and new waveforms that provide scalability and flexibility to meet the varying demands of 5G services. Unlike the one size fits all 4G core networks, the 5G core network must be flexible and adaptable and is expected to simultaneously provide optimized support for the diverse 5G use case categories. In this paper, we provide an overview of 5G research, standardization trials, and deployment challenges. Due to the enormous scope of 5G systems, it is necessary to provide some direction in a tutorial article, and in this overview, the focus is largely user centric, rather than device centric. In addition to surveying the state of play in the area, we identify leading technologies, evaluating their strengths and weaknesses, and outline the key challenges ahead, with research test beds delivering promising performance but pre-commercial trials lagging behind the desired 5G targets.},
	pages = {1201--1221},
	number = {6},
	journaltitle = {{IEEE} Journal on Selected Areas in Communications},
	author = {Shafi, Mansoor and Molisch, Andreas F. and Smith, Peter J. and Haustein, Thomas and Zhu, Peiying and De Silva, Prasan and Tufvesson, Fredrik and Benjebbour, Anass and Wunder, Gerhard},
	urldate = {2024-05-24},
	date = {2017-06},
	note = {Conference Name: {IEEE} Journal on Selected Areas in Communications},
	keywords = {5G, 5G mobile communication, Antenna arrays, Bandwidth, Computer architecture, Microprocessors, Tutorials, beamforming, cloud ran, massive {MIMO}, next generation core, testbeds, trials, waveforms},
}

@online{noauthor_about_nodate-1,
	title = {About {NATS}},
	url = {https://nats.io/about/},
	abstract = {{NATS} is a connective technology built for the ever increasingly hyper-connected world. It is a single technology that enables applications to securely communicate across any combination of cloud vendors, on-premise, edge, web and mobile, and devices. {NATS} consists of a family of open source products that are tightly integrated but can be deployed easily and independently. {NATS} is being used globally by thousands of companies, spanning use-cases including microservices, edge computing, mobile, {IoT} and can be used to augment or replace traditional messaging.},
	titleaddon = {{NATS}.io},
	urldate = {2024-04-14},
	langid = {english},
}

@article{rosen_about_2015,
	title = {About The Importance of Autonomy and Digital Twins for the Future of Manufacturing},
	volume = {48},
	issn = {2405-8963},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896315003808},
	doi = {10.1016/j.ifacol.2015.06.141},
	series = {15th {IFAC} Symposium {onInformation} Control Problems {inManufacturing}},
	abstract = {Industrie 4.0 - the “brand” name of the German initiative driving the future of manufacturing - is one of several initiatives around the globe emphasizing the importance of industrial manufacturing for economy and society. Besides the socio-economical if not political question which has to be answered - including the question about the future of labor - there are a couple of substantial technical and technological questions that have to be taken care of as well.},
	pages = {567--572},
	number = {3},
	journaltitle = {{IFAC}-{PapersOnLine}},
	shortjournal = {{IFAC}-{PapersOnLine}},
	author = {Rosen, Roland and von Wichert, Georg and Lo, George and Bettenhausen, Kurt D.},
	urldate = {2024-05-24},
	date = {2015-01-01},
	keywords = {Automation, Autonomy, Digital Twin, Manufacturing, Simulation},
}

@online{noauthor_become_nodate,
	title = {Become an {API}-first company {\textbar} Kong},
	url = {https://konghq.com},
	abstract = {Unlock developer productivity, strengthen security, and streamline {API} management. Join 600+ businesses in transforming digital experiences.},
	titleaddon = {Kong Inc.},
	urldate = {2024-04-15},
	langid = {english},
}

@online{noauthor_ansible_nodate,
	title = {Ansible playbooks — Ansible Community Documentation},
	url = {https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_intro.html},
	urldate = {2024-06-16},
}

@online{noauthor_apache_nodate,
	title = {Apache Kafka},
	url = {https://kafka.apache.org/},
	abstract = {Apache Kafka: A Distributed Streaming Platform.},
	titleaddon = {Apache Kafka},
	urldate = {2024-04-14},
	langid = {english},
}

@online{noauthor_api_nodate,
	title = {{API} - {HyperShift}},
	url = {https://hypershift-docs.netlify.app/reference/api/},
	urldate = {2024-06-16},
}

@online{noauthor_benchmarking_nodate,
	title = {Benchmarking {NATS} Streaming and Apache Kafka - {DZone}},
	url = {http://bravenewgeek.com/benchmarking-commit-logs/},
	titleaddon = {dzone.com},
	urldate = {2024-04-14},
	langid = {english},
}

@article{basiri_chaos_2016,
	title = {Chaos Engineering},
	volume = {33},
	issn = {0740-7459},
	doi = {10.1109/MS.2016.60},
	abstract = {Modern software-based services are implemented as distributed systems with complex behavior and failure modes. Many large tech organizations are using experimentation to verify such systems' reliability. Netflix engineers call this approach chaos engineering. They've determined several principles underlying it and have used it to run experiments. This article is part of a theme issue on {DevOps}. © 2016 {IEEE}.},
	pages = {35--41},
	number = {3},
	journaltitle = {{IEEE} Software},
	author = {Basiri, A. and Behnam, N. and De Rooij, R. and Hochstein, L. and Kosewski, L. and Reynolds, J. and Rosenthal, C.},
	date = {2016},
	keywords = {Chaos Monkey, {DevOps}, Netflix, chaos engineering, software development, software engineering},
}

@article{fogli_chaos_2024,
	title = {Chaos Engineering for Resilience Assessment of Digital Twins},
	volume = {20},
	issn = {1941-0050},
	url = {https://ieeexplore.ieee.org/document/10091206},
	doi = {10.1109/TII.2023.3264101},
	abstract = {Within the Industry 4.0 vision, digital twins ({DTs}) have gained great attention as a promising approach to improve remote monitoring and control by means of virtual representations of physical objects. However, while {DTs} are becoming more and more sophisticated and even adopted for mission-critical applications, their resilience assessment has not received the required consideration yet. This article originally proposes chaos engineering to assess and improve the resilience of {DTs} by testing multiple aspects of industrial environments in a coordinated, automated, and replicable manner. First, the article discusses why and how chaos engineering is promising to improve the resilience of {DTs}. Then, it identifies and introduces a set of chaos engineering profiles specifically designed to take into account the many aspects an industrial environment is composed of. Finally, it shows the feasibility of assessing the resilience of a proof-of-concept {DT} through a testbed based on widely-adopted, open-source tools.},
	pages = {1134--1143},
	number = {2},
	journaltitle = {{IEEE} Transactions on Industrial Informatics},
	author = {Fogli, Mattia and Giannelli, Carlo and Poltronieri, Filippo and Stefanelli, Cesare and Tortonesi, Mauro},
	urldate = {2024-02-27},
	date = {2024-02},
	note = {Conference Name: {IEEE} Transactions on Industrial Informatics},
	keywords = {Chaos, Chaos engineering, Digital twins, Fourth Industrial Revolution, Industry 4.0, Informatics, Microservice architectures, Production, Resilience, digital twin ({DT}), entanglement, industrial Internet of Things},
}

@online{noauthor_chapter_nodate,
	title = {Chapter 1. Cluster lifecycle with multicluster engine operator overview {\textbar} Red Hat Product Documentation},
	url = {https://docs.redhat.com/en/documentation/red_hat_advanced_cluster_management_for_kubernetes/2.8/html/clusters/cluster_mce_overview#create-hosted-clusters-kubevirt-customized-ingress-dns},
	urldate = {2024-07-28},
}

@inproceedings{poltronieri_chaostwin_2021,
	title = {{ChaosTwin}: A Chaos Engineering and Digital Twin Approach for the Design of Resilient {IT} Services},
	url = {https://ieeexplore.ieee.org/document/9615519},
	doi = {10.23919/CNSM52442.2021.9615519},
	shorttitle = {{ChaosTwin}},
	abstract = {Chaos Engineering represents an interesting software engineering methodology to improve the resilience of a complex {IT} system operating in a live production environment by injecting simulated faults, observing the system reaction, and devising mitigating solutions. However, Chaos Engineering is an expensive practice with a high setup and operation overhead and it often focuses on the evaluation of the system behavior from a relatively narrow technical perspective instead of a more comprehensive business level one. To enlarge the audience of Chaos Engineering there is the need for novel solutions that can give service providers the tools to deal with the deployment and testing of complex {IT} services. To fill this gap, this paper presents {ChaosTwin}, a novel solution exploring an innovative approach to apply Chaos Engineering to a digital-twin, i.e., a virtual representation of a physical object or a system. By creating realistic digital twin of an {IT} service, injecting faults on the digital twin and evaluating how different service configuration and fault management strategies would perform from a business level perspective, {ChaosTwin} provides useful guidance to service providers in finding cost-effective service configurations that can minimize the negative effects of unpredictable events. Experimental results, collected from the evaluation of a realistic case study, demonstrate how {ChaosTwin} is capable of minimizing both the associated costs and the effects of injected Chaos faults.},
	eventtitle = {2021 17th International Conference on Network and Service Management ({CNSM})},
	pages = {234--238},
	booktitle = {2021 17th International Conference on Network and Service Management ({CNSM})},
	author = {Poltronieri, Filippo and Tortonesi, Mauro and Stefanelli, Cesare},
	urldate = {2024-02-27},
	date = {2021-10},
	note = {{ISSN}: 2165-963X},
	keywords = {Business, Business Driven {IT} Management ({BDIM}), Chaos, Chaos Engineering, Cloud Computing, Costs, Digital Twin, Digital twin, Optimization, Production, Testing, Tools},
}

@inproceedings{sonkoly_cloud-powered_2019,
	title = {Cloud-Powered Digital Twins: Is It Reality?},
	url = {https://ieeexplore.ieee.org/abstract/document/9064112/references#references},
	doi = {10.1109/CloudNet47604.2019.9064112},
	shorttitle = {Cloud-Powered Digital Twins},
	abstract = {The flexibility of future production systems envisioned by Industry 4.0 requires safe but efficient Human-Robot Collaboration ({HRC}). An important enabler of {HRC} is a sophisticated collision avoidance mechanism which can detect objects and potential collision events and as a response, it calculates detour trajectories avoiding physical contacts. Digital twins provide a novel way to test the impact of different control decisions in a simulated virtual environment even in parallel. The required computational power can be provided by cloud platforms but at the cost of higher delay and jitter. Moreover, clouds bring a versatile set of novel techniques easing the life of both developers and operators. Can digital twins exploit the benefits of these concepts? Can the robots tolerate the delay characteristics coming with the cloud platforms? In this paper, we answer these questions by building on public and private cloud solutions providing different techniques for parallel computation. Our contribution is threefold. First, we introduce a measurement methodology to characterize different approaches in terms of latency. Second, a real {HRC} use-case is elaborated and a relevant {KPI} is defined. Third, we evaluate the pros/cons of different solutions and their impact on the performance.},
	eventtitle = {2019 {IEEE} 8th International Conference on Cloud Networking ({CloudNet})},
	pages = {1--6},
	booktitle = {2019 {IEEE} 8th International Conference on Cloud Networking ({CloudNet})},
	author = {Sonkoly, Balázs and Nagy, Bálint György and Dóka, János and Pelle, István and Szabó, Géza and Rácz, Sándor and Czentye, János and Toka, László},
	urldate = {2024-01-22},
	date = {2019-11},
}

@online{noauthor_compare_2022,
	title = {Compare {NATS} {\textbar} {NATS} Docs},
	url = {https://docs.nats.io/nats-concepts/overview/compare-nats},
	abstract = {{NATS} Comparison to Kafka, Rabbit, {gRPC}, and others},
	urldate = {2024-04-14},
	date = {2022-05-05},
	langid = {english},
}

@online{noauthor_create_nodate,
	title = {Create a Kubevirt cluster - {HyperShift}},
	url = {https://hypershift-docs.netlify.app/how-to/kubevirt/create-kubevirt-cluster/},
	urldate = {2024-07-08},
}

@online{noauthor_create_nodate-1,
	title = {Create a Kubevirt cluster - {HyperShift}},
	url = {https://hypershift-docs.netlify.app/how-to/kubevirt/create-kubevirt-cluster/},
	urldate = {2024-07-28},
}

@online{noauthor_custom_2024,
	title = {Custom Machine Config Pool in {OpenShift} 4},
	url = {https://access.redhat.com/solutions/5688941},
	abstract = {Is there any way to create a custom Machine Config Pool without inheriting worker {MCP}? Is it possible to use the newly created custom Machine Config Pool without having a worker role? How to create a custom Machine Config Pool},
	titleaddon = {Red Hat Customer Portal},
	urldate = {2024-07-08},
	date = {2024-06-14},
	langid = {english},
}

@online{memphisdev_comparing_2023,
	title = {Comparing {NATS} and Kafka: Understanding the Differences},
	url = {https://memphis-dev.medium.com/comparing-nats-and-kafka-understanding-the-differences-f08c4479dea6},
	shorttitle = {Comparing {NATS} and Kafka},
	abstract = {Messaging systems are game-changers in modern software development, enabling communication between different components of a system. They…},
	titleaddon = {Medium},
	author = {Memphis.dev},
	urldate = {2024-04-14},
	date = {2023-06-20},
	langid = {english},
}

@article{mendonca_developing_2021,
	title = {Developing Self-Adaptive Microservice Systems: Challenges and Directions},
	volume = {38},
	issn = {1937-4194},
	url = {https://ieeexplore.ieee.org/document/8913688},
	doi = {10.1109/MS.2019.2955937},
	shorttitle = {Developing Self-Adaptive Microservice Systems},
	abstract = {A self-adaptive system can dynamically monitor and adapt its behavior to preserve and enhance its quality attributes under uncertain operating conditions. This article identifies key challenges for the development of microservice applications as self-adaptive systems, using a cloud-based intelligent video-surveillance application as a motivating example. It also suggests potential new directions for addressing most of the identified challenges by leveraging existing microservice practices and technologies.},
	pages = {70--79},
	number = {2},
	journaltitle = {{IEEE} Software},
	author = {Mendonca, Nabor C. and Jamshidi, Pooyan and Garlan, David and Pahl, Claus},
	urldate = {2024-02-27},
	date = {2021-03},
	note = {Conference Name: {IEEE} Software},
	keywords = {Computer architecture, {DevOps}, Face recognition, Self-adaptive systems, Streaming media, Video surveillance, continuous delivery, microservices},
}

@article{grieves_digital_2015,
	title = {Digital Twin: Manufacturing Excellence through Virtual Factory Replication},
	shorttitle = {Digital Twin},
	abstract = {This paper introduces the concept of a " Digital Twin " as a virtual representation of what has been produced. Compare a Digital Twin to its engineering design to better understand what was produced versus what was designed, tightening the loop between design and execution.},
	author = {Grieves, Michael},
	date = {2015-03-01},
}

@article{vrabic_digital_2018,
	title = {Digital twins: Understanding the added value of integrated models for through-life engineering services},
	volume = {16},
	issn = {2351-9789},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978918312897},
	doi = {10.1016/j.promfg.2018.10.167},
	series = {Proceedings of the 7th International Conference on Through-life Engineering Services},
	shorttitle = {Digital twins},
	abstract = {Digital twins are digital representations of physical products or systems that consist of multiple models from various domains describing them on multiple scales. By means of communication, digital twins change and evolve together with their physical counterparts throughout their lifecycle. Domain-specific partial models that make up the digital twin, such as the {CAD} model or the degradation model, are usually well known and provide accurate descriptions of certain parts of the physical asset. However, in complex systems, the value of integrating the partial models increases because it facilitates the study of their complex behaviours which only emerge from the interactions between various parts of the system. The paper proposes that the partial models of the digital twin share a common model space that integrates them through a definition of their interrelations and acts as a bridge between the digital twin and the physical asset. The approach is illustrated in a case of a mechatronic product - a differential drive mobile robot developed as a testbed for digital twin research. It is demonstrated how the integrated models add value to different stages of the lifecycle, allowing for evaluation of performance in the design stage and real-time reflection with the physical asset during its operation.},
	pages = {139--146},
	journaltitle = {Procedia Manufacturing},
	shortjournal = {Procedia Manufacturing},
	author = {Vrabič, Rok and Erkoyuncu, John Ahmet and Butala, Peter and Roy, Rajkumar},
	urldate = {2024-01-25},
	date = {2018-01-01},
	keywords = {digital twin, modelling, multi-domain model},
}

@misc{ma_eureka_2023,
	title = {Eureka: Human-Level Reward Design via Coding Large Language Models},
	url = {http://arxiv.org/abs/2310.12931},
	doi = {10.48550/arXiv.2310.12931},
	shorttitle = {Eureka},
	abstract = {Large Language Models ({LLMs}) have excelled as high-level semantic planners for sequential decision-making tasks. However, harnessing them to learn complex low-level manipulation tasks, such as dexterous pen spinning, remains an open problem. We bridge this fundamental gap and present Eureka, a human-level reward design algorithm powered by {LLMs}. Eureka exploits the remarkable zero-shot generation, code-writing, and in-context improvement capabilities of state-of-the-art {LLMs}, such as {GPT}-4, to perform evolutionary optimization over reward code. The resulting rewards can then be used to acquire complex skills via reinforcement learning. Without any task-specific prompting or pre-defined reward templates, Eureka generates reward functions that outperform expert human-engineered rewards. In a diverse suite of 29 open-source {RL} environments that include 10 distinct robot morphologies, Eureka outperforms human experts on 83\% of the tasks, leading to an average normalized improvement of 52\%. The generality of Eureka also enables a new gradient-free in-context learning approach to reinforcement learning from human feedback ({RLHF}), readily incorporating human inputs to improve the quality and the safety of the generated rewards without model updating. Finally, using Eureka rewards in a curriculum learning setting, we demonstrate for the first time, a simulated Shadow Hand capable of performing pen spinning tricks, adeptly manipulating a pen in circles at rapid speed.},
	number = {{arXiv}:2310.12931},
	publisher = {{arXiv}},
	author = {Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
	urldate = {2024-02-16},
	date = {2023-10-19},
	eprinttype = {arxiv},
	eprint = {2310.12931 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@inproceedings{villamizar_evaluating_2015,
	title = {Evaluating the monolithic and the microservice architecture pattern to deploy web applications in the cloud},
	isbn = {978-1-4673-9464-2},
	doi = {10.1109/ColumbianCC.2015.7333476},
	abstract = {Cloud computing provides new opportunities to deploy scalable application in an efficient way, allowing enterprise applications to dynamically adjust their computing resources on demand. In this paper we analyze and test the microservice architecture pattern, used during the last years by large Internet companies like Amazon, Netflix and {LinkedIn} to deploy large applications in the cloud as a set of small services that can be developed, tested, deployed, scaled, operated and upgraded independently, allowing these companies to gain agility, reduce complexity and scale their applications in the cloud in a more efficient way. We present a case study where an enterprise application was developed and deployed in the cloud using a monolithic approach and a microservice architecture using the Play web framework. We show the results of performance tests executed on both applications, and we describe the benefits and challenges that existing enterprises can get and face when they implement microservices in their applications. © 2015 {IEEE}.},
	eventtitle = {2015 10th Colombian Computing Conference, 10CCC 2015},
	pages = {583--590},
	author = {Villamizar, M. and Garces, O. and Castro, H. and Verano, M. and Salamanca, L. and Casallas, R. and Gil, S.},
	date = {2015},
	keywords = {{IaaS}, {PaaS}, {SOA}, cloud computing, continuous delivery, infrastructure as a services, microservice architecture, microservices, platform as a service, scalable applications, service oriented architectures, software architecture, software engineering},
}

@online{noauthor_free5gc_nodate,
	title = {free5GC},
	url = {https://free5gc.org/},
	urldate = {2024-05-04},
}

@article{jiang_industrial_2021,
	title = {Industrial applications of digital twins},
	rights = {2021 The Author(s)},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0360},
	doi = {10.1098/rsta.2020.0360},
	abstract = {A digital twin ({DT}) is classically defined as the virtual replica of a real-world
product, system, being, communities, even cities that are continuously updated with
data from its physical counterpart, as well as its environment. It bridges the virtual
...},
	journaltitle = {Philosophical Transactions of the Royal Society A},
	author = {Jiang, Yuchen and Yin, Shen and Li, Kuan and Luo, Hao and Kaynak, Okyay},
	urldate = {2024-01-10},
	date = {2021-10-04},
}

@online{cloud_native_computing_foundation_frequently_2018,
	title = {Frequently Asked Questions},
	url = {https://www.cncf.io/about/faq/},
	abstract = {Please see the Cloud Native Definition. Companies are realizing that they need to be a software company, even if they are not in the software business. For example, Airbnb is revolutionizing the…},
	titleaddon = {{CNCF}},
	author = {Cloud Native Computing Foundation},
	urldate = {2024-02-16},
	date = {2018-06-11},
	langid = {american},
}

@online{noauthor_home_nodate,
	title = {Home - {HyperShift}},
	url = {https://hypershift-docs.netlify.app/},
	urldate = {2024-06-16},
}

@online{noauthor_homepage_nodate,
	title = {Homepage {\textbar} Ansible Collaborative},
	url = {https://www.ansible.com/},
	urldate = {2024-06-16},
}

@online{noauthor_horizontal_nodate,
	title = {Horizontal Pod Autoscaling},
	url = {https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/},
	abstract = {In Kubernetes, a {HorizontalPodAutoscaler} automatically updates a workload resource (such as a Deployment or {StatefulSet}), with the aim of automatically scaling the workload to match demand.
Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or {CPU}) to the Pods that are already running for the workload.},
	urldate = {2024-04-15},
	langid = {english},
	note = {Section: docs},
}

@online{noauthor_installing_nodate,
	title = {Installing a user-provisioned cluster on bare metal - Installing on bare metal {\textbar} Installing {\textbar} {OpenShift} Container Platform 4.15},
	url = {https://docs.openshift.com/container-platform/4.15/installing/installing_bare_metal/installing-bare-metal.html},
	urldate = {2024-07-07},
}

@article{pylianidis_introducing_2021,
	title = {Introducing digital twins to agriculture},
	volume = {184},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169920331471},
	doi = {https://doi.org/10.1016/j.compag.2020.105942},
	abstract = {Digital twins are being adopted by increasingly more industries, transforming them and bringing new opportunities. Digital twins provide previously unheard levels of control over physical entities and help to manage complex systems by integrating an array of technologies. Recently, agriculture has seen several technological advancements, but it is still unclear if this community is making an effort to adopt digital twins in its operations. In this work, we employ a mixed-method approach to investigate the added-value of digital twins for agriculture. We examine the extent of digital twin adoption in agriculture, shed light on the concept and the benefits it brings, and provide an application-based roadmap for a more extended adoption. We report a literature review of digital twins in agriculture, covering years 2017-2020. We identify 28 use cases, and compare them with use cases in other disciplines. We compare reported benefits, service categories, and technology readiness levels to assess the level of digital twin adoption in agriculture. We distill the digital twin characteristics that can provide added-value to agriculture from the examined digital twin applications in agriculture and in other disciplines. Then, inspired by digital twin applications in other disciplines, we propose a roadmap for digital twins in agriculture, consisting of examples of growing complexity. We conclude this paper by identifying the distinctive characteristics of agricultural digital twins.},
	pages = {105942},
	journaltitle = {Computers and Electronics in Agriculture},
	author = {Pylianidis, Christos and Osinga, Sjoukje and Athanasiadis, Ioannis N.},
	date = {2021},
}

@online{noauthor_keda_nodate,
	title = {{KEDA}},
	url = {https://keda.sh/},
	abstract = {Application autoscaling made simple},
	titleaddon = {{KEDA}},
	urldate = {2024-04-15},
	langid = {english},
}

@online{noauthor_keda_nodate-1,
	title = {{KEDA} {\textbar} {KEDA} Concepts},
	url = {https://keda.sh/docs/2.13/concepts/},
	abstract = {What {KEDA} is and how it works},
	titleaddon = {{KEDA}},
	urldate = {2024-07-07},
	langid = {english},
}

@online{konghq_kong_nodate,
	title = {Kong Gateway},
	url = {https://docs.konghq.com},
	abstract = {Kong Gateway is a lightweight, fast, and flexible cloud-native {API} gateway. Kong is a reverse proxy that lets you manage, configure, and route requests},
	titleaddon = {Kong Docs},
	author = {{KongHQ}},
	urldate = {2024-07-07},
	langid = {english},
}

@inproceedings{bhardwaj_kubeklone_2023,
	title = {{KubeKlone}: A Digital Twin for Simulating Edge and Cloud Microservices},
	doi = {10.1145/3542637.3542642},
	shorttitle = {{KubeKlone}},
	pages = {29--35},
	author = {Bhardwaj, Ayush and Benson, Theophilus},
	date = {2023-11-07},
}

@online{noauthor_kubernetes_nodate,
	title = {Kubernetes},
	url = {https://kubernetes.io/},
	abstract = {Production-Grade Container Orchestration},
	urldate = {2024-04-14},
	langid = {english},
}

@online{noauthor_kubespray_nodate,
	title = {Kubespray},
	url = {https://kubespray.io/#/},
	urldate = {2024-06-16},
}

@online{noauthor_kubevirtio_nodate,
	title = {{KubeVirt}.io},
	url = {https://kubevirt.io//},
	abstract = {Virtual Machine Management on Kubernetes},
	titleaddon = {{KubeVirt}.io},
	urldate = {2024-06-16},
	langid = {english},
}

@online{noauthor_machine_nodate,
	title = {Machine configuration tasks {\textbar} Postinstallation configuration {\textbar} {OpenShift} Container Platform 4.15},
	url = {https://docs.openshift.com/container-platform/4.15/post_installation_configuration/machine-configuration-tasks.html},
	urldate = {2024-06-30},
}

@online{noauthor_openshift_nodate,
	title = {{OpenShift} Container Platform 4: How does Machine Config Pool work?},
	url = {https://www.redhat.com/en/blog/openshift-container-platform-4-how-does-machine-config-pool-work},
	shorttitle = {{OpenShift} Container Platform 4},
	abstract = {In this post we will discuss what Machine Config Pool is and how you should use it for {OpenShift} 4 infra nodes.},
	urldate = {2024-06-16},
	langid = {english},
}

@online{team_microservices_2015,
	title = {Microservices at Netflix: Lessons for Architectural Design},
	url = {https://www.nginx.com/blog/microservices-at-netflix-architectural-best-practices/},
	shorttitle = {Microservices at Netflix},
	abstract = {Learn design principles and best practices for microservices architecture from Adrian Cockcroft, former lead Cloud Architect at Netflix},
	titleaddon = {{NGINX}},
	author = {Team, Web},
	urldate = {2024-03-09},
	date = {2015-02-19},
	langid = {american},
}

@online{noauthor_mounting_2024,
	title = {Mounting separate disk for {OpenShift} 4 container storage},
	url = {https://access.redhat.com/solutions/4952011},
	abstract = {How to mount separate disk to /var/lib/containers on {OpenShift} 4 nodes.},
	titleaddon = {Red Hat Customer Portal},
	urldate = {2024-07-08},
	date = {2024-06-14},
	langid = {english},
}

@online{noauthor_observability_nodate,
	title = {Observability Survey Report 2024 - key findings},
	url = {https://grafana.com/observability-survey/},
	abstract = {Learn what observability practitioners have to say about the biggest trends in the industry, including cost, tool overload, open source, {AI}, and more.},
	titleaddon = {Grafana Labs},
	urldate = {2024-04-15},
	langid = {english},
}

@online{noauthor_open5gcore_nodate,
	title = {Open5GCore {\textbar} Open5GCore},
	url = {https://www.open5gcore.org/},
	urldate = {2024-05-04},
}

@online{prometheus_overview_nodate,
	title = {Overview {\textbar} Prometheus},
	url = {https://prometheus.io/docs/introduction/overview/},
	abstract = {An open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.},
	author = {Prometheus},
	urldate = {2024-04-14},
	langid = {english},
}

@inproceedings{bohm_profiling_2021,
	title = {Profiling lightweight container platforms: {MicroK}8s and K3s in comparison to kubernetes},
	volume = {2839},
	shorttitle = {Profiling lightweight container platforms},
	abstract = {Kubernetes (K8s) is nowadays the first choice for managing containerized deployments that rely on high-availability, scalability, and fault tolerance. To enable the usage of container orchestration in resource-constrained environments, lightweight distributions emerged. The platforms {MicroK}8s ({mK}8s) and K3s, which are analyzed in this paper, claim to provide an easy deployment of K8s in a simplified form and way. In terms of resource utilization and deployment time of a K8s cluster, the lightweight platforms promise savings compared to K8s. We analyzed lightweight K8s distributions in a quantitative way by performing an experiment that monitors the utilization and time consumption compared to a native K8s cluster lifecycle. This involves starting, stopping, and adding nodes as well as creating, running, and deleting deployments. We show that not all platforms exhibit a quantitative advantage over K8s. K3s caused a similar resource consumption but had some performance advantages for starting new nodes and adding nodes to the cluster. The platform {MicroK}8s has shown a higher resource utilization and time consumption for all steps in our modeled lifecycle simulation. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International ({CC} {BY} 4.0).},
	eventtitle = {{CEUR} Workshop Proceedings},
	pages = {65--73},
	author = {Böhm, S. and Wirtz, G.},
	date = {2021},
	note = {{ISSN}: 1613-0073},
	keywords = {Container lifecycle, Container orchestration, Lightweight kubernetes, Performance model},
}

@online{noauthor_preparing_nodate,
	title = {Preparing to install with Agent-based Installer - Installing an on-premise cluster with the Agent-based Installer {\textbar} Installing {\textbar} {OpenShift} Container Platform 4.15},
	url = {https://docs.openshift.com/container-platform/4.15/installing/installing_with_agent_based_installer/preparing-to-install-with-agent-based-installer.html},
	urldate = {2024-07-08},
}

@online{noauthor_publish-subscribe_2022,
	title = {Publish-Subscribe {\textbar} {NATS} Docs},
	url = {https://docs.nats.io/nats-concepts/core-nats/pubsub},
	urldate = {2024-05-05},
	date = {2022-01-18},
	langid = {english},
}

@online{red_hat_inc_red_nodate,
	title = {Red Hat {OpenShift} enterprise Kubernetes container platform},
	url = {https://www.redhat.com/en/technologies/cloud-computing/openshift},
	abstract = {Red Hat® {OpenShift}® is a unified platform to build, modernize, and deploy applications at scale},
	author = {{Red Hat Inc.}},
	urldate = {2024-05-27},
	langid = {english},
}

@online{noauthor_prometheus_nodate,
	title = {Prometheus Adapter Walkthrough},
	url = {https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/docs/walkthrough.md},
	abstract = {An implementation of the custom.metrics.k8s.io {API} using Prometheus - kubernetes-sigs/prometheus-adapter},
	titleaddon = {{GitHub}},
	urldate = {2024-04-15},
	langid = {english},
}

@online{noauthor_queue_2022,
	title = {Queue Groups {\textbar} {NATS} Docs},
	url = {https://docs.nats.io/nats-concepts/core-nats/queue},
	urldate = {2024-05-05},
	date = {2022-05-02},
	langid = {english},
}

@online{noauthor_red_nodate,
	title = {Red Hat named a Leader in 2023 Gartner® Magic Quadrant™ for Container Management},
	url = {https://www.redhat.com/en/engage/gartner-magic-quadrant-container-management-analyst-report},
	abstract = {In its extensive evaluation of multicloud container platform providers, Forrester Research identified Red Hat as a “Leader” in the 2023 Forrester Wave™.},
	urldate = {2024-06-16},
	langid = {english},
}

@online{noauthor_red_nodate-1,
	title = {Red Hat {OpenShift} vs. Kubernetes: What's the difference?},
	url = {https://www.redhat.com/en/technologies/cloud-computing/openshift/red-hat-openshift-kubernetes},
	shorttitle = {Red Hat {OpenShift} vs. Kubernetes},
	abstract = {Red Hat® {OpenShift}® is a certified Kubernetes powered application platform —a commercialized software product built based on multiple open source projects.},
	urldate = {2024-06-16},
	langid = {english},
}

@article{liu_review_2021,
	title = {Review of digital twin about concepts, technologies, and industrial applications},
	volume = {58},
	issn = {0278-6125},
	url = {https://www.sciencedirect.com/science/article/pii/S0278612520301072},
	doi = {10.1016/j.jmsy.2020.06.017},
	series = {Digital Twin towards Smart Manufacturing and Industry 4.0},
	abstract = {Various kinds of engineering software and digitalized equipment are widely applied through the lifecycle of industrial products. As a result, massive data of different types are being produced. However, these data are hysteretic and isolated from each other, leading to low efficiency and low utilization of these valuable data. Simulation based on theoretical and static model has been a conventional and powerful tool for the verification, validation, and optimization of a system in its early planning stage, but no attention is paid to the simulation application during system run-time. With the development of new-generation information and digitalization technologies, more data can be collected, and it is time to find a way for the deep application of all these data. As a result, the concept of digital twin has aroused much concern and is developing rapidly. Dispute and discussions around concepts, paradigms, frameworks, applications, and technologies of digital twin are on the rise both in academic and industrial communities. After a complete search of several databases and careful selection according to the proposed criteria, 240 academic publications about digital twin are identified and classified. This paper conducts a comprehensive and in-depth review of these literatures to analyze digital twin from the perspective of concepts, technologies, and industrial applications. Research status, evolution of the concept, key enabling technologies of three aspects, and fifteen kinds of industrial applications in respective lifecycle phase are demonstrated in detail. Based on this, observations and future work recommendations for digital twin research are presented in the form of different lifecycle phases.},
	pages = {346--361},
	journaltitle = {Journal of Manufacturing Systems},
	shortjournal = {Journal of Manufacturing Systems},
	author = {Liu, Mengnan and Fang, Shuiliang and Dong, Huiyue and Xu, Cunzhi},
	urldate = {2024-02-27},
	date = {2021-01-01},
	keywords = {Digital twin, Industrial application, Literature review, Product lifecycle, Simulation},
}

@inproceedings{glaessgen_digital_2012,
	location = {Honolulu, Hawaii},
	title = {The Digital Twin Paradigm for Future {NASA} and U.S. Air Force Vehicles},
	isbn = {978-1-60086-937-2},
	url = {http://arc.aiaa.org/doi/abs/10.2514/6.2012-1818},
	doi = {10.2514/6.2012-1818},
	eventtitle = {53rd {AIAA}/{ASME}/{ASCE}/{AHS}/{ASC} Structures, Structural Dynamics and Materials Conference{\textless}{BR}{\textgreater}20th {AIAA}/{ASME}/{AHS} Adaptive Structures Conference{\textless}{BR}{\textgreater}14th {AIAA}},
	booktitle = {53rd {AIAA}/{ASME}/{ASCE}/{AHS}/{ASC} Structures, Structural Dynamics and Materials Conference\&lt;{BR}\&gt;20th {AIAA}/{ASME}/{AHS} Adaptive Structures Conference\&lt;{BR}\&gt;14th {AIAA}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Glaessgen, Edward and Stargel, David},
	urldate = {2024-01-28},
	date = {2012-04-23},
	langid = {english},
}

@online{noauthor_setting-up-your-first-cluster_nodate,
	title = {Setting-up-your-first-cluster},
	url = {https://kubespray.io/#/docs/getting_started/setting-up-your-first-cluster},
	urldate = {2024-06-16},
}

@online{noauthor_grafana_nodate,
	title = {The Grafana Stack},
	url = {https://grafana.com/about/grafana-stack/},
	abstract = {Grafana Labs is the company behind leading open source projects Grafana and Loki and the creator of the first open and composable observability platform.},
	titleaddon = {Grafana Labs},
	urldate = {2024-04-15},
	langid = {english},
}

@online{noauthor_top_nodate,
	title = {Top 5 products in the Virtualization Management Software market},
	url = {https://enlyft.com/techVirtualization Management Software},
	abstract = {enlyft industry research shows that Kubernetes, Red Hat {OpenShift}, and {VMware} Horizon are top players in the Virtualization Management Software marketplace.},
	urldate = {2024-05-27},
	langid = {english},
}

@online{cloud_native_computing_foundation_who_nodate,
	title = {Who We Are},
	url = {https://www.cncf.io/about/who-we-are/},
	abstract = {The Cloud Native Computing Foundation ({CNCF}) hosts critical components of the global technology infrastructure. We bring together the world’s top developers, end users, and vendors and run the largest…},
	author = {{Cloud Native Computing Foundation}},
	urldate = {2024-02-16},
	langid = {american},
}

@online{palladino_top_nodate,
	title = {Top {API} Gateway Platform 2022 {\textbar}},
	url = {https://konghq.com/blog/enterprise/why-kong-is-the-best-api-gateway},
	abstract = {A deep dive on Kong’s {API} Gateway technology, our historical adoption and why Kong is really the King of the {API} jungle.},
	titleaddon = {Kong Inc.},
	author = {Palladino, Marco},
	urldate = {2024-04-15},
	langid = {english},
}

@misc{bauer_understanding_nodate,
	title = {Understanding the importance and impact of network digital twins},
	url = {https://onestore.nokia.com/asset/213918},
	shorttitle = {Nokia},
	abstract = {The rapidly developing field of network digital twins ({NDT}) has the potential to revolutionize network capabilities and operations. In this white pape},
	author = {Bauer, Eric},
	urldate = {2024-04-17},
	langid = {english},
}

@article{sinatra_quantifying_2016,
	title = {Quantifying the evolution of individual scientific impact},
	volume = {354},
	url = {https://www.science.org/doi/10.1126/science.aaf5239},
	doi = {10.1126/science.aaf5239},
	abstract = {Despite the frequent use of numerous quantitative indicators to gauge the professional impact of a scientist, little is known about how scientific impact emerges and evolves in time. Here, we quantify the changes in impact and productivity throughout a career in science, finding that impact, as measured by influential publications, is distributed randomly within a scientist’s sequence of publications. This random-impact rule allows us to formulate a stochastic model that uncouples the effects of productivity, individual ability, and luck and unveils the existence of universal patterns governing the emergence of scientific success. The model assigns a unique individual parameter Q to each scientist, which is stable during a career, and it accurately predicts the evolution of a scientist’s impact, from the h-index to cumulative citations, and independent recognitions, such as prizes.},
	pages = {aaf5239},
	number = {6312},
	journaltitle = {Science},
	author = {Sinatra, Roberta and Wang, Dashun and Deville, Pierre and Song, Chaoming and Barabási, Albert-László},
	urldate = {2024-05-06},
	date = {2016-11-04},
	note = {Publisher: American Association for the Advancement of Science},
}

@online{noauthor_index_nodate,
	title = {Index of /events/apnet2022/papers/},
	url = {https://conferences.sigcomm.org/events/apnet2022/papers/},
	urldate = {2024-01-25},
}

@incollection{glaessgen_digital_nodate,
	title = {The Digital Twin Paradigm for Future {NASA} and U.S. Air Force Vehicles},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2012-1818},
	booktitle = {53rd {AIAA}/{ASME}/{ASCE}/{AHS}/{ASC} Structures, Structural Dynamics and Materials Conference},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Glaessgen, Edward and Stargel, David},
	urldate = {2024-01-25},
	doi = {10.2514/6.2012-1818},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2012-1818},
}
